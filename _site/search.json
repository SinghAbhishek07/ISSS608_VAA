[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on/Hands-on 1/Hand-on1.html",
    "href": "Hands-on/Hands-on 1/Hand-on1.html",
    "title": "Hand-on1",
    "section": "",
    "text": "pacman::p_load(tidyverse,dplyr)\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n#glimpse(exam_data)\n#View(exam_data)"
  },
  {
    "objectID": "Hands-on/Hands-on 1/Hand-on1.html#essential-grammatical-elements-in-ggplot2",
    "href": "Hands-on/Hands-on 1/Hand-on1.html#essential-grammatical-elements-in-ggplot2",
    "title": "Hand-on1",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nA Layered Grammar of Graphics\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background.\n\n\nggplot(data=exam_data)\n\n\n\n\n\n\nNotice that a blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by `fortify()"
  },
  {
    "objectID": "Hands-on/Hands-on 1/Hand-on1.html#essential-grammatical-elements-in-ggplot2-1",
    "href": "Hands-on/Hands-on 1/Hand-on1.html#essential-grammatical-elements-in-ggplot2-1",
    "title": "Hand-on1",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\n\nGeometric Objects: [geom_bar]\n\nPLotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\nGeometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5, dotsize = 0.5) +\n  scale_y_continuous(NULL, breaks = NULL)\n\n\n\n\n\n\nGeometric Objects: geom_histogram()\nIn the code chunk below, [geom_histogram()] is used to create a simple histogram by using values in MATHS field of exam_data.\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30.\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()\n\n\n\n\n\n\nModifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\") \n\n\n\n\n\n\nModifying a geometric object by changing aes()\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\nGeometric Objects: geom-density\n[geom-density()]computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density() \n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\nGeometric Objects: geom_boxplot\n\n[geom_boxplot()]displays continuous value list.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot() \n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\ngeom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +\n  geom_point(position=\"jitter\", \n             size = 0.5)\n\n\n\n\n\n\nGeometric Objects: geom_violin\n[geom_violin] is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin() \n\n\n\n\n\n\nGeometric Objects: geom_violin() and geom_boxplot()\nThe code chunk below combined a violin plot and a boxplot to show the distribution of Maths scores by gender.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin(fill=\"light blue\") +\n  geom_boxplot(alpha=0.5)  \n\n\n\n\n\n\nGeometric Objects: geom_point()\n\n[geom_point()] is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()\n\n\n\n\n\n\nStatistics, stat\n\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n\nWorking with stat - the stat_summary() method\nThe code chunk below adds mean values by using [stat_summary()] function and overriding the default geom.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)   \n\n\n\n\n\n\nWorking with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)   \n\n\n\n\n\n\nHow to add a best fit curve on a scatterplot?\nIn the code chunk below, [geom_smooth()] is used to plot a best fit curve on the scatterplot.\n\nThe default method used is loess.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)"
  },
  {
    "objectID": "Hands-on/Hands-on 1/Hand-on1.html#facets",
    "href": "Hands-on/Hands-on 1/Hand-on1.html#facets",
    "title": "Hand-on1",
    "section": "Facets",
    "text": "Facets\n\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data.\nFacets are an alternative to aesthetics for displaying additional discrete variables.\nggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n\nfacet_wrap()\n\n[facet_wrap] wraps a 1d sequence of panels into 2d.\nThis is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\n\nThe code chunk below plots a trellis plot using facet-wrap().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\nfacet_grid() function\n\n[facet_grid()] forms a matrix of panels defined by row and column facetting variables.\nIt is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\n\nThe code chunk below plots a trellis plot using facet_grid().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)\n\n\n\n\n\n\nCoordinates\n\nThe Coordinates functions map the position of objects onto the plane of the plot.\nThere are a number of different possible coordinate systems to use, they are:\n\n[coord_cartesian()]: the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\n\n[coord_fixed()]: a cartesian system with a “fixed” aspect ratio .\n[coord_quickmap()](: a coordinate system that approximates a good aspect ratio for maps.\n\n\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\nHow to change to the y- and x-axis range?\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n\n\n\n\n\n\nThemes\n\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include:\n\ntheme_gray() (default)\ntheme_bw()\ntheme_classic()\n\nA list of theme can be found at this link.\nEach theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\nThe code chunk below plot a horizontal bar chart using theme_gray()\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()"
  },
  {
    "objectID": "Hands-on/Hands-on 2/Hand-on2.html",
    "href": "Hands-on/Hands-on 2/Hand-on2.html",
    "title": "Hand-on2",
    "section": "",
    "text": "4 new packages beside tidyverse.\n\nggrepel: an R package provides geoms for ggplot2 to repel - overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse)"
  },
  {
    "objectID": "Hands-on/Hands-on 2/Hand-on2.html#working-on-some-new-libraries",
    "href": "Hands-on/Hands-on 2/Hand-on2.html#working-on-some-new-libraries",
    "title": "Hand-on2",
    "section": "",
    "text": "4 new packages beside tidyverse.\n\nggrepel: an R package provides geoms for ggplot2 to repel - overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse)"
  },
  {
    "objectID": "Hands-on/Hands-on 2/Hand-on2.html#importing-data",
    "href": "Hands-on/Hands-on 2/Hand-on2.html#importing-data",
    "title": "Hand-on2",
    "section": "Importing data",
    "text": "Importing data\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\nDT::datatable(exam_data, class= \"compact\")"
  },
  {
    "objectID": "Hands-on/Hands-on 2/Hand-on2.html#beyond-ggplot2-annotation",
    "href": "Hands-on/Hands-on 2/Hand-on2.html#beyond-ggplot2-annotation",
    "title": "Hand-on2",
    "section": "Beyond ggplot2 Annotation",
    "text": "Beyond ggplot2 Annotation\n\nggrepel\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n[ggrepel] is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right. We simply replace geom_text() by [geom_text_repel()] and geom_label() by [geom_label_repel]\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on/Hands-on 2/Hand-on2.html#ggplot2-themes",
    "href": "Hands-on/Hands-on 2/Hand-on2.html#ggplot2-themes",
    "title": "Hand-on2",
    "section": "ggplot2 Themes",
    "text": "ggplot2 Themes\nggplot2 comes with eight [built-in themes], they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +  \n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\nWorking with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\nWorking with hrbthems package\n[hrbrthemes] package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18, \n              base_size = 15, \n              grid = \"Y\") \n\n\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk below?\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on/Hands-on 2/Hand-on2.html#combining-graphs",
    "href": "Hands-on/Hands-on 2/Hand-on2.html#combining-graphs",
    "title": "Hand-on2",
    "section": "Combining Graphs",
    "text": "Combining Graphs\nIn this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics.\n\nPlotCode\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\nWorking with patchwork\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\np1 + p2 / p3\n\n\n\n\n| will place the plots beside each other, while / will stack them.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\npatchwork also provides auto-tagging capabilities, in order to identify subplots in text:\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)"
  },
  {
    "objectID": "Hands-on/Hands-on 6/Hand-on06.html",
    "href": "Hands-on/Hands-on 6/Hand-on06.html",
    "title": "Hands-On 5",
    "section": "",
    "text": "** Modelling, Visualising and Analysing Network Data with R**\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type\n\n\n\nglimpse(GAStech_nodes)\n\nRows: 54\nColumns: 4\n$ id         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 44, 45, 46, 8, 9, 10, 11, 12, 13, 14, …\n$ label      &lt;chr&gt; \"Mat.Bramar\", \"Anda.Ribera\", \"Rachel.Pantanal\", \"Linda.Lago…\n$ Department &lt;chr&gt; \"Administration\", \"Administration\", \"Administration\", \"Admi…\n$ Title      &lt;chr&gt; \"Assistant to CEO\", \"Assistant to CFO\", \"Assistant to CIO\",…\n\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nTip\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field. the values in the Weekday field are in ordinal scale.\n\n\n\nWrangling attributes\nwe will aggregate the individual by date, senders, receivers, main subject and day of the week\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…\n\n\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;     &lt;int&gt;\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# ℹ 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nPlotting a basic network graph\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\nFruchterman and Reingold layout\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on/Hands-on 8/Hands-on_Ex08/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on/Hands-on 8/Hands-on_Ex08/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class Exercise/In-class 1/In-Class1.html",
    "href": "In-class Exercise/In-class 1/In-Class1.html",
    "title": "In-Class1",
    "section": "",
    "text": "Loading Tidyverse\npacman::p_load(tidyverse)\nImporting data\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class Exercise/In-class 1/In-Class1.html#working-with-theme",
    "href": "In-class Exercise/In-class 1/In-Class1.html#working-with-theme",
    "title": "In-Class1",
    "section": "Working with theme",
    "text": "Working with theme\nChanging the colors of plot panel background of theme_minimal() to light blue and the color of grid lines to white.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal() +\n  theme(\n    panel.background = element_rect(fill = \"lightblue\", colour = \"lightblue\", \n                                    size = 0.5, linetype = \"solid\"),\n    panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour = \"white\"), \n    panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = \"white\"))"
  },
  {
    "objectID": "In-class Exercise/In-class 1/In-Class1.html#designing-data-drive-graphics-for-analysis-i",
    "href": "In-class Exercise/In-class 1/In-Class1.html#designing-data-drive-graphics-for-analysis-i",
    "title": "In-Class1",
    "section": "Designing Data-drive Graphics for Analysis I",
    "text": "Designing Data-drive Graphics for Analysis I\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=reorder(RACE,RACE,\n                     function(x)-length(x)))) +\n  geom_bar() +\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100, 1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))\n\n\n\n\nThis code chunk uses fct_infreq() of forcats package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nexam_data %&gt;%\n  mutate(RACE = fct_infreq(RACE)) %&gt;%\n  ggplot(aes(x = RACE)) + \n  geom_bar()+\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(after_stat(count), \", \", \n      round(after_stat(count)/sum(after_stat(count))*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "In-class Exercise/In-class 1/In-Class1.html#designing-data-drive-graphics-for-analysis-ii",
    "href": "In-class Exercise/In-class 1/In-Class1.html#designing-data-drive-graphics-for-analysis-ii",
    "title": "In-Class1",
    "section": "Designing Data-drive Graphics for Analysis II",
    "text": "Designing Data-drive Graphics for Analysis II\n\nAdding mean and median lines on the histogram plot.\nChange fill color and line color\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(MATHS, na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=1) +\n  geom_vline(aes(xintercept=median(MATHS, na.rm=T)),\n             color=\"grey30\",\n             linetype=\"dashed\", \n             size=1)"
  },
  {
    "objectID": "In-class Exercise/In-class 1/In-Class1.html#designing-data-drive-graphics-for-analysis-iii",
    "href": "In-class Exercise/In-class 1/In-Class1.html#designing-data-drive-graphics-for-analysis-iii",
    "title": "In-Class1",
    "section": "Designing Data-drive Graphics for Analysis III",
    "text": "Designing Data-drive Graphics for Analysis III\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(d, aes(x = ENGLISH, fill = GENDER)) +\n  geom_histogram(data = d_bg, fill = \"grey\", alpha = .5) +\n  geom_histogram(colour = \"black\") +\n  facet_wrap(~ GENDER) +\n  guides(fill = 'none') +  \n  theme_bw()"
  },
  {
    "objectID": "In-class Exercise/In-class 1/In-Class1.html#designing-data-drive-graphics-for-analysis-iv",
    "href": "In-class Exercise/In-class 1/In-Class1.html#designing-data-drive-graphics-for-analysis-iv",
    "title": "In-Class1",
    "section": "Designing Data-drive Graphics for Analysis IV",
    "text": "Designing Data-drive Graphics for Analysis IV\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point() +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  geom_hline(yintercept=50,\n             linetype=\"dashed\",\n             color=\"grey60\",\n             size=1) + \n  geom_vline(xintercept=50, \n             linetype=\"dashed\",\n             color=\"grey60\",\n             size=1)"
  },
  {
    "objectID": "In-class Exercise/In-class 1/In-Class1.html#tableau",
    "href": "In-class Exercise/In-class 1/In-Class1.html#tableau",
    "title": "In-Class1",
    "section": "Tableau",
    "text": "Tableau\nLinks to Tableau Visualisations:\nSuperstore Orders"
  },
  {
    "objectID": "In-class Exercise/In-class 4/In-Class4.html",
    "href": "In-class Exercise/In-class 4/In-Class4.html",
    "title": "In_ClassExercise4",
    "section": "",
    "text": "pacman::p_load(rstatix, gt, patchwork, tidyverse)\n\n\nexam_data&lt;-read_csv(\"data/Exam_data.csv\")\n\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data,\n       aes(sample=ENGLISH))+\n  stat_qq() +\n  stat_qq_line()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that the points deviate significantly from the straight diagonal line. This is a clear inidcation that the set of data is not normally distributed.\n\n\n\nComibining statistical graph and analysis table\nNeed to install webshot"
  },
  {
    "objectID": "In-class Exercise/In-class 5/In-Class5.html",
    "href": "In-class Exercise/In-class 5/In-Class5.html",
    "title": "In-Class5",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts,jsonlite)\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…\n\n\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;     &lt;int&gt;\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# ℹ 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\nMC1 &lt;- fromJSON(\"data/MC1.json\")\n\n\nMC1_nodes &lt;- as.tibble(MC1$nodes) %&gt;%\n  select(id,type,country)\n\n\nMC1_edges &lt;- as.tibble(MC1$links) %&gt;%\n  select(source,target,type,weight,key)"
  },
  {
    "objectID": "In-class Exercise/In-Class 7/In-Class 7/In_class07.html",
    "href": "In-class Exercise/In-Class 7/In-Class 7/In_class07.html",
    "title": "In-Class7",
    "section": "",
    "text": "pacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\n\naverp &lt;- read_csv(\"data/AVERP.csv\") %&gt;%\n  mutate(`Date` = dmy(`Date`))\n\n\naverp &lt;- read_csv(\"data/AVERP.csv\") %&gt;%\n  mutate(`Date` = dmy(`Date`))\n\nHorizon Graph\n\naverp %&gt;% \n  filter(Date &gt;= \"2018-01-01\") %&gt;%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "In-class Exercise/In-Class 8/data/geospatial/MPSZ-2019.html",
    "href": "In-class Exercise/In-Class 8/data/geospatial/MPSZ-2019.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Abhishek’s Visual Data Visualization",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications.In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html",
    "href": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "The City of Engagement, a small city located in the Country of Nowhere, serves as a service center for an agriculture region known for its fruit farms and vineyards. The local council is currently preparing the Local Plan 2023, and they have conducted a sample survey of 1000 representative residents to gather data on household demographics and spending patterns. This exercise aims to uncover insights into the city’s demographic and financial characteristics. The goal is to provide city managers and planners with a user-friendly and interactive solution that allows them to explore the complex data and identify hidden patterns."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#overview",
    "href": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#overview",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "The City of Engagement, a small city located in the Country of Nowhere, serves as a service center for an agriculture region known for its fruit farms and vineyards. The local council is currently preparing the Local Plan 2023, and they have conducted a sample survey of 1000 representative residents to gather data on household demographics and spending patterns. This exercise aims to uncover insights into the city’s demographic and financial characteristics. The goal is to provide city managers and planners with a user-friendly and interactive solution that allows them to explore the complex data and identify hidden patterns."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#objective",
    "href": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#objective",
    "title": "Take-home Exercise 1",
    "section": "Objective",
    "text": "Objective\nThe objective of this exercise is to use the tidyverse family of packages, including ggplot2 and its extensions, to process the survey data and create appropriate static and interactive statistical graphics. By using this, I aim to\n\nExplore the distribution of joviality among the participants and identify any patterns or trends.\nAnalyze the demographic characteristics of the City of Engagement\nInvestigate whether there is a correlation between joviality and financial behavior. Are participants with higher joviality more likely to spend or save money?\n\nThe city wants to use the information to help with its significant community development initiatives, particularly how to distribute a sizable grant for city renewal that it recently received it. This would make it possible for urban planners to concentrate their efforts on particular regions of the community to raise population merriment generally."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#data-preparation",
    "href": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#data-preparation",
    "title": "Take-home Exercise 1",
    "section": "1. Data Preparation",
    "text": "1. Data Preparation\n\n1.1 Install R packages and import dataset\nThe code chunk below uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages installed are\n\nplotly: Used for creating interactive web-based graphs.\nggstatsplot: Used for creating graphics with details from statistical tests.\nknitr: Used for dynamic report generation\npacthwork: Used to combine plots\nggdist: Used for visualising distribution and uncertainty\nggthemes: Provide additional themes for ggplot2\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nrstatix: used for data manipulation, summarization, and group-wise comparisons\nHmisc : used to compute descriptive statistics for a variable in a dataset\nDT : DataTables that create interactive table on html page.\nsummarytools- used for creating summary statistics and tables for data exploration and reporting\nkableExtra- is used for creating tables in various output formats, such as HTML, PDF, or Word documents.\nggplot2- provides a flexible and layered approach to create a wide variety of high-quality static and interactive plots\nggpubr- It provides a collection of easy-to-use functions for creating publication-ready plots and performing statistical analysis\nggridges- used to visualize the distribution of a continuous variable across different categories or groups.\nreshape2- It provides functions to convert data between wide and long formats, which is useful for restructuring and aggregating data.\nAll packages can be found within CRAN.\n\npacman::p_load() function from the pacman package is used in the following code chunk to install and call the libraries of multiple R packages:\n\n#Load packages\npacman::p_load(plotly, ggstatsplot, knitr, patchwork, ggdist, ggthemes, tidyverse,rstatix,Hmisc, DT ,summarytools,kableExtra,ggplot2 ,ggpubr,ggridges, reshape2)\n\n\n\n1.2 Importing data sets\nTwo datasets are provided: Participants.csv and FinancialJournal.csv.\nI used them as resident_info and financial respectively.\n\n1.2.1 Working with Participants dataset\nImport data from csv using readr::read_csv() and store it in variable resident_info.\nreadr is one of the tidyverse package.\n\nresident_info &lt;- read_csv(\"data/Participants.csv\")\n\n\nDatatableStructureSummary StataticsSummary Table\n\n\nDisplaying the datatable using the DT package\n\nDT::datatable(resident_info, class= \"compact\", filter='top')\n\n\n\n\n\n\n\n\nIt used to provide a compact and structured summary of the internal structure\n\nstr(resident_info)\n\nspc_tbl_ [1,011 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ participantId : num [1:1011] 0 1 2 3 4 5 6 7 8 9 ...\n $ householdSize : num [1:1011] 3 3 3 3 3 3 3 3 3 3 ...\n $ haveKids      : logi [1:1011] TRUE TRUE TRUE TRUE TRUE TRUE ...\n $ age           : num [1:1011] 36 25 35 21 43 32 26 27 20 35 ...\n $ educationLevel: chr [1:1011] \"HighSchoolOrCollege\" \"HighSchoolOrCollege\" \"HighSchoolOrCollege\" \"HighSchoolOrCollege\" ...\n $ interestGroup : chr [1:1011] \"H\" \"B\" \"A\" \"I\" ...\n $ joviality     : num [1:1011] 0.00163 0.32809 0.39347 0.13806 0.8574 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   participantId = col_double(),\n  ..   householdSize = col_double(),\n  ..   haveKids = col_logical(),\n  ..   age = col_double(),\n  ..   educationLevel = col_character(),\n  ..   interestGroup = col_character(),\n  ..   joviality = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nThere are a total of 1011 rows and 7 variables. The output reveals that variables participantId and householdSize have been read as numeric, continuous data types, and it should changed as nominal data instead because participantId serve as unique identifiers and householdSize represent discrete categories such as 1, 2, 3.\n\n\nIt provides a summary of the variables in the data frame, including their distribution, range, and missing values. This includes measures such as count, mean, standard deviation, minimum, maximum, and quartiles.\n\nHmisc::describe(resident_info)\n\nresident_info \n\n 7  Variables      1011  Observations\n--------------------------------------------------------------------------------\nparticipantId \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n    1011        0     1011        1      505    337.3     50.5    101.0 \n     .25      .50      .75      .90      .95 \n   252.5    505.0    757.5    909.0    959.5 \n\nlowest :    0    1    2    3    4, highest: 1006 1007 1008 1009 1010\n--------------------------------------------------------------------------------\nhouseholdSize \n       n  missing distinct     Info     Mean      Gmd \n    1011        0        3    0.886    1.964   0.8635 \n                            \nValue          1     2     3\nFrequency    337   373   301\nProportion 0.333 0.369 0.298\n--------------------------------------------------------------------------------\nhaveKids \n       n  missing distinct \n    1011        0        2 \n                      \nValue      FALSE  TRUE\nFrequency    710   301\nProportion 0.702 0.298\n--------------------------------------------------------------------------------\nage \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n    1011        0       43    0.999    39.07     14.3       20       22 \n     .25      .50      .75      .90      .95 \n      29       39       50       56       58 \n\nlowest : 18 19 20 21 22, highest: 56 57 58 59 60\n--------------------------------------------------------------------------------\neducationLevel \n       n  missing distinct \n    1011        0        4 \n                                                                      \nValue                Bachelors            Graduate HighSchoolOrCollege\nFrequency                  232                 170                 525\nProportion               0.229               0.168               0.519\n                              \nValue                      Low\nFrequency                   84\nProportion               0.083\n--------------------------------------------------------------------------------\ninterestGroup \n       n  missing distinct \n    1011        0       10 \n\nlowest : A B C D E, highest: F G H I J\n                                                                      \nValue          A     B     C     D     E     F     G     H     I     J\nFrequency    102    91   102    96    83   106   108   111    96   116\nProportion 0.101 0.090 0.101 0.095 0.082 0.105 0.107 0.110 0.095 0.115\n--------------------------------------------------------------------------------\njoviality \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n    1011        0     1011        1   0.4938   0.3364  0.05642  0.10871 \n     .25      .50      .75      .90      .95 \n 0.24007  0.47754  0.74682  0.90645  0.96024 \n\nlowest : 0.000204000 0.000265000 0.000985000 0.001365799 0.001626703\nhighest: 0.992601749 0.997604884 0.997670843 0.998644049 0.999233967\n--------------------------------------------------------------------------------\n\n\nFrom the output, there are zero missing values across all columns in resident_info\n\n\n\n\n\n\nTip\n\n\n\nThe describe() function provides summary statistics for numerical variables by default. If we need to include categorical variables as well, it can set the fast = FALSE argument Hmisc::describe(resident_info, fast = FALSE)\nBy setting fast = FALSE, the describe() function will calculate summary statistics for both numerical and categorical variables in the resident_info data frame.\n\n\n\n\nCreating detailed summary table\n\ndf1 &lt;- resident_info %&gt;% \n  select(-starts_with('Q'), -starts_with('HQ')) %&gt;%\n  mutate_if(is.integer, as.numeric) %&gt;%\n  mutate_if(is.logical, as.numeric)\n\nflat_numeric &lt;- df1 %&gt;% select_if(is.numeric)\n\nprint(dfSummary(flat_numeric, graph.magnif = 0.75), method = 'render')\n\n\nData Frame Summary\nflat_numeric\nDimensions: 1011 x 5\n  Duplicates: 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\nparticipantId [numeric]\n\n\n\nMean (sd) : 505 (292)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 505 ≤ 1010\n\n\nIQR (CV) : 505 (0.6)\n\n\n\n1011 distinct values\n\n1011 (100.0%)\n0 (0.0%)\n\n\n2\nhouseholdSize [numeric]\n\n\n\nMean (sd) : 2 (0.8)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 3\n\n\nIQR (CV) : 2 (0.4)\n\n\n\n\n\n\n1\n:\n337\n(\n33.3%\n)\n\n\n2\n:\n373\n(\n36.9%\n)\n\n\n3\n:\n301\n(\n29.8%\n)\n\n\n\n\n1011 (100.0%)\n0 (0.0%)\n\n\n3\nhaveKids [numeric]\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n710\n(\n70.2%\n)\n\n\n1\n:\n301\n(\n29.8%\n)\n\n\n\n\n1011 (100.0%)\n0 (0.0%)\n\n\n4\nage [numeric]\n\n\n\nMean (sd) : 39.1 (12.4)\n\n\nmin ≤ med ≤ max:\n\n\n18 ≤ 39 ≤ 60\n\n\nIQR (CV) : 21 (0.3)\n\n\n\n43 distinct values\n\n1011 (100.0%)\n0 (0.0%)\n\n\n5\njoviality [numeric]\n\n\n\nMean (sd) : 0.5 (0.3)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 0.5 ≤ 1\n\n\nIQR (CV) : 0.5 (0.6)\n\n\n\n1011 distinct values\n\n1011 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.2.3)2023-06-18\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\nBased on the statistics from the summary table, below are some useful insights:\n\nparticipantId: There are 1,011 unique participant IDs. The range of IDs is from 0 to 1,010, indicating that there are no missing or duplicated IDs.\nhouseholdSize: The data contains three distinct household sizes: 1, 2, and 3. The most common household size is 2, followed by 1 and then 3. The proportions indicate that 33.3% of the households have a size of 1, 36.9% have a size of 2, and 29.8% have a size of 3.\nhaveKids: There are two distinct values: FALSE and TRUE. The majority of participants (70.2%) do not have kids, while 29.8% have kids.\nage: The data includes 43 distinct ages, ranging from 18 to 60. The mean age is approximately 39 years, with a standard deviation of 14.3. The 5th percentile is 20, the median is 39, and the 95th percentile is 58.\neducationLevel: There are four distinct education levels: Bachelors, Graduate, HighSchoolOrCollege, and Low. The majority of participants (51.9%) have a HighSchoolOrCollege education level, followed by Bachelors (22.9%), Graduate (16.8%), and Low (8.3%).\ninterestGroup: There are 10 distinct interest groups labeled from A to J. The frequencies and proportions indicate the distribution of participants across these interest groups.\njoviality: Joviality is a numeric variable ranging from 0 to 1. The mean joviality score is approximately 0.494, with a standard deviation of 0.3364. The 5th percentile is 0.05642, the median is 0.47754, and the 95th percentile is 0.96024.\n\n\n\n\n\nChanging Data Types:\n\nparticipantId is classified as &lt;dbl&gt;, numerical continuous data, instead of nominal. This is cast as &lt;chr&gt; class using as.factor()\nhouseholdSize is classified as &lt;dbl&gt;, but categorical in nature with different levels. This is cast as &lt;chr&gt; class using `as.factor()\neducationLevel is classified as &lt;chr  &gt; categorical data,which has 4 different category. It need to be changed using ordered() function.\n\n\n\nChanging data typeChecking the changes\n\n\n\nresident_new &lt;- resident_info %&gt;%\n# Changing Data Types of participantsID , household, educationlevel\n   mutate(participantId = as.factor(participantId),\n         householdSize = as.factor(householdSize),\n         educationLevel = as.ordered(educationLevel))\n\n\n\n\n# Check the data types of variables\nstr(resident_new)\n\ntibble [1,011 × 7] (S3: tbl_df/tbl/data.frame)\n $ participantId : Factor w/ 1011 levels \"0\",\"1\",\"2\",\"3\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ householdSize : Factor w/ 3 levels \"1\",\"2\",\"3\": 3 3 3 3 3 3 3 3 3 3 ...\n $ haveKids      : logi [1:1011] TRUE TRUE TRUE TRUE TRUE TRUE ...\n $ age           : num [1:1011] 36 25 35 21 43 32 26 27 20 35 ...\n $ educationLevel: Ord.factor w/ 4 levels \"Bachelors\"&lt;\"Graduate\"&lt;..: 3 3 3 3 1 3 3 1 1 1 ...\n $ interestGroup : chr [1:1011] \"H\" \"B\" \"A\" \"I\" ...\n $ joviality     : num [1:1011] 0.00163 0.32809 0.39347 0.13806 0.8574 ...\n\n\n\n\n\n\nAdding a new column Age Group\n\n\nAdding Age-GroupViolin Plot\n\n\nFirst we can calculate the range using the quartile() function and then group them according and check their visualization after grouping them\n\n# Calculate the percentile values for age\nage_percentiles &lt;- quantile(resident_new$age, probs = c(0.25, 0.5, 0.75, 1))\n\n# Display the percentile values\nprint(age_percentiles)\n\n 25%  50%  75% 100% \n  29   39   50   60 \n\n\nBased on the result, now will group them accordingly\n\n# Define the percentile ranges\nage_percentiles &lt;- quantile(resident_new$age, probs = c(0, 0.25, 0.5, 0.75, 1))\n\n# Create age group labels based on the percentile ranges\nage_labels &lt;- c(\"18-29 yrs\", \"30-39 yrs\", \"40-50 yrs\", \"51-60 yrs\")\n\n# Create age groups based on the percentile ranges\nresident_new$age_group &lt;- cut(resident_new$age, breaks = age_percentiles, labels = age_labels, include.lowest = TRUE)\n\n\n# Display the updated table with age groups\nstr(resident_new)\n\ntibble [1,011 × 8] (S3: tbl_df/tbl/data.frame)\n $ participantId : Factor w/ 1011 levels \"0\",\"1\",\"2\",\"3\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ householdSize : Factor w/ 3 levels \"1\",\"2\",\"3\": 3 3 3 3 3 3 3 3 3 3 ...\n $ haveKids      : logi [1:1011] TRUE TRUE TRUE TRUE TRUE TRUE ...\n $ age           : num [1:1011] 36 25 35 21 43 32 26 27 20 35 ...\n $ educationLevel: Ord.factor w/ 4 levels \"Bachelors\"&lt;\"Graduate\"&lt;..: 3 3 3 3 1 3 3 1 1 1 ...\n $ interestGroup : chr [1:1011] \"H\" \"B\" \"A\" \"I\" ...\n $ joviality     : num [1:1011] 0.00163 0.32809 0.39347 0.13806 0.8574 ...\n $ age_group     : Factor w/ 4 levels \"18-29 yrs\",\"30-39 yrs\",..: 2 1 2 1 3 2 1 1 1 2 ...\n\n\n\n\n\n\n\n\nNote\n\n\n\ncut() is used to create age groups based on the age column in the resident_new table. The breaks argument takes the percentile ranges obtained earlier, and the labels argument assigns labels to each group. The include.lowest = TRUE parameter ensures that the lowest age value is included in the first group.\n\n\n\n\n\nggplot(resident_new, aes(x = age_group, y = age, fill = age_group)) +\n  geom_violin() +\n  xlab(\"Age Group\") +\n  ylab(\"Age\") +\n  ggtitle(\"Distribution of Age by Age Group\") +\n  scale_fill_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n1.2.2 Working with FinancialJournal dataset\nImport data from csv using readr::read_csv() and store it in variable financial.\nreadr is one of the tidyverse package.\n\nfinancial &lt;- read_csv(\"data/FinancialJournal.csv\")\n\n\nDatatableStructureSummary StataticsSummary Table\n\n\nDisplaying the datatable using the DT package\n\nDT:: datatable(head(financial,100),options = list(pagelength=10,scrollX='400px'),class='cell-border stripe',filter='top')\n\n\n\n\n\n\n\n\nIt used to provide a compact and structured summary of the internal structure\n\nstr(financial)\n\nspc_tbl_ [1,513,636 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ participantId: num [1:1513636] 0 0 0 1 1 1 2 2 2 3 ...\n $ timestamp    : POSIXct[1:1513636], format: \"2022-03-01\" \"2022-03-01\" ...\n $ category     : chr [1:1513636] \"Wage\" \"Shelter\" \"Education\" \"Wage\" ...\n $ amount       : num [1:1513636] 2473 -555 -38 2047 -555 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   participantId = col_double(),\n  ..   timestamp = col_datetime(format = \"\"),\n  ..   category = col_character(),\n  ..   amount = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nThere are a total of 1,513,636 rows and 4 variables. The output reveals that variables participantId been read as numeric, continuous data types, and it should changed as nominal data instead because participantId serve as unique identifiers .\n\n\nIt provides a summary of the variables in the data frame, including their distribution, range, and missing values. This includes measures such as count, mean, standard deviation, minimum, maximum, and quartiles.\n\nHmisc::describe(financial)\n\nfinancial \n\n 4  Variables      1513636  Observations\n--------------------------------------------------------------------------------\nparticipantId \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n 1513636        0     1011        1    480.9    341.2       43       86 \n     .25      .50      .75      .90      .95 \n     222      464      726      918      967 \n\nlowest :    0    1    2    3    4, highest: 1006 1007 1008 1009 1010\n--------------------------------------------------------------------------------\ntimestamp \n                  n             missing            distinct                Info \n            1513636                   0               87366                   1 \n               Mean                 Gmd                 .05                 .10 \n2022-08-26 05:00:48            10684501 2022-03-14 14:00:00 2022-03-31 07:20:00 \n                .25                 .50                 .75                 .90 \n2022-05-24 13:25:00 2022-08-25 15:00:00 2022-11-27 07:25:00 2023-01-22 10:20:00 \n                .95 \n2023-02-09 20:10:00 \n\nlowest : 2022-03-01 00:00:00 2022-03-01 04:50:00 2022-03-01 05:30:00 2022-03-01 05:40:00 2022-03-01 05:45:00\nhighest: 2023-02-28 23:35:00 2023-02-28 23:40:00 2023-02-28 23:45:00 2023-02-28 23:50:00 2023-02-28 23:55:00\n--------------------------------------------------------------------------------\ncategory \n       n  missing distinct \n 1513636        0        6 \n\nlowest : Education      Food           Recreation     RentAdjustment Shelter       \nhighest: Food           Recreation     RentAdjustment Shelter        Wage          \n                                                                      \nValue           Education           Food     Recreation RentAdjustment\nFrequency            3319         790051         296013            131\nProportion          0.002          0.522          0.196          0.000\n                                        \nValue             Shelter           Wage\nFrequency           11463         412659\nProportion          0.008          0.273\n--------------------------------------------------------------------------------\namount \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n 1513636        0     6690    0.981    20.05    66.15  -21.050  -15.182 \n     .25      .50      .75      .90      .95 \n  -5.594   -4.000   21.598  107.467  159.561 \n\nlowest : -1562.726 -1556.356 -1499.254 -1475.672 -1458.686\nhighest:  4059.861  4069.449  4078.119  4085.387  4096.526\n--------------------------------------------------------------------------------\n\n\nFrom the output, there are zero missing values across all columns in financial\n\n\n\n\n\n\nTip\n\n\n\nThe describe() function provides summary statistics for numerical variables by default. If we need to include categorical variables as well, it can set the fast = FALSE argument Hmisc::describe(resident_info, fast = FALSE)\nBy setting fast = FALSE, the describe() function will calculate summary statistics for both numerical and categorical variables in the resident_info data frame.\n\n\n\n\nCreating detailed summary table\n\ndf2 &lt;- financial %&gt;% \n  select(-starts_with('Q'), -starts_with('HQ')) %&gt;%\n  mutate_if(is.integer, as.numeric) %&gt;%\n  mutate_if(is.logical, as.numeric)\n\nflat_numeric1 &lt;- df2 %&gt;% select_if(is.numeric)\n\nprint(dfSummary(flat_numeric1, graph.magnif = 0.75), method = 'render')\n\n\nData Frame Summary\nflat_numeric1\nDimensions: 1513636 x 2\n  Duplicates: 1418986\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\nparticipantId [numeric]\n\n\n\nMean (sd) : 480.9 (295.9)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 464 ≤ 1010\n\n\nIQR (CV) : 504 (0.6)\n\n\n\n1011 distinct values\n\n1513636 (100.0%)\n0 (0.0%)\n\n\n2\namount [numeric]\n\n\n\nMean (sd) : 20 (111.8)\n\n\nmin ≤ med ≤ max:\n\n\n-1562.7 ≤ -4 ≤ 4096.5\n\n\nIQR (CV) : 27.2 (5.6)\n\n\n\n6690 distinct values\n\n1513636 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.2.3)2023-06-18\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\nBased on the statistics from the summary table, below are some useful insights:\n\nParticipant ID: There are 1,011 unique participants in the financial data. The participant ID ranges from 0 to 1,010. .\nTimestamp: The financial data spans a time period from March 1, 2022, to February 28, 2023. The timestamp variable shows the date and time of each financial transaction. .\nCategory: There are six distinct categories in the financial data, including Education, Food, Recreation, RentAdjustment, Shelter, and Wage. The most frequent category is Food, accounting for approximately 52.2% of the transactions, followed by Recreation (19.6%) and Wage (27.3%).\nAmount: The amount variable represents the monetary value of each transaction. The mean amount is 20.05, indicating an average transaction value. The range of the amounts is from -1562.726 to 4096.526, with a wide distribution. The majority of the amounts fall within the range of -21.050 to 159.561.\n\n\n\n\n\nChanging Data Types:\n\nparticipantId is classified as &lt;dbl&gt;, numerical continuous data, instead of nominal. This is cast as &lt;chr&gt; class using as.factor()\ntimestamp has a big value contains date and time both, which is not required for our anaylsis. So i will change it into Year-month bascially extract that data only from timestamp and save it.\ncategory is classified as &lt;chr  &gt;but categorical data,which has 4 different category. It need to be changed using as.factor().\namount has decimal point upto 10. It will be rounded upto 2 for readability and easily computation.\n\n\n\nChanging data typeChecking the changes\n\n\n\nfinancial_new &lt;- financial %&gt;%\n  mutate(\n\n# Changing participantId to nominal\nparticipantId = as.factor(participantId),\n\n# Extracting Year-Month from timestamp\ntimestamp = format(as.Date(timestamp), \"%Y-%m\"),\n\n# Changing category to factor\ncategory = as.factor(category),\n\n# Rounding amount to 2 decimal places\namount = round(amount, 2)\n\n)\n\n\n\n\n# Check the data types of variables\nstr(financial_new)\n\ntibble [1,513,636 × 4] (S3: tbl_df/tbl/data.frame)\n $ participantId: Factor w/ 1011 levels \"0\",\"1\",\"2\",\"3\",..: 1 1 1 2 2 2 3 3 3 4 ...\n $ timestamp    : chr [1:1513636] \"2022-03\" \"2022-03\" \"2022-03\" \"2022-03\" ...\n $ category     : Factor w/ 6 levels \"Education\",\"Food\",..: 6 5 1 6 5 1 6 5 1 6 ...\n $ amount       : num [1:1513636] 2473 -555 -38 2047 -555 ...\n\n\n\n\n\n\nDivide Category into new columns and count Total Amount for each category\n\n\nCategory’sChecking the changes\n\n\n\nfinancial_new &lt;- financial_new %&gt;%\n  group_by(participantId, timestamp, category) %&gt;%\n  summarise(total_amount = sum(amount), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = category, values_from = total_amount)\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk groups the data by participantId, timestamp, and category, calculates the sum of amount for each group, and then reshapes the data to have separate columns for each category, with the corresponding total_amount values. The resulting data frame is assigned to financial_new.The pivot_wider() function is used to reshape the data frame from a long format to a wide format. It takes the distinct category values as column names and populates the corresponding total_amount values for each participantId and timestamp combination.\n\n\n\n\n\nDT::datatable(financial_new, class= \"compact\", filter='top')\n\n\n\n\n\n\n\n\n\n\n\n\n1.2 Joining the Tables\nWe have 2 dataset resident_new with columns participantId, householdSize, haveKids, age, educationLevel,interestGroup, joviality, age_group and financial_new with columns participantId, timestamp,Education ,Food, Recreation, Shelter, Wage, RentAdjustment.\n\nJoin TableCheck Table\n\n\n\nresident_financial &lt;- left_join(resident_new, financial_new, by = \"participantId\")\n\nThe code chunk will create a new data frame resident_financial that combines the columns from both tables based on matching participantId values. The resulting data frame will include all the columns from both tables.\n\n\n\nDT::datatable(resident_financial, class= \"compact\", filter='top')\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe new table resident_financial consists of the columns participantId, householdSize, haveKids, age, educationLevel,interestGroup, joviality, age_group timestamp, Education ,Food, Recreation, Shelter, Wage, RentAdjustment.\n\n\n\n\n\n\nChecking Summary Statistics of resident_financial\n\n\nStructureSummary StatisticsSummary Table\n\n\nIt used to provide a compact and structured summary of the internal structure\n\nstr(resident_financial)\n\ntibble [10,691 × 15] (S3: tbl_df/tbl/data.frame)\n $ participantId : Factor w/ 1011 levels \"0\",\"1\",\"2\",\"3\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ householdSize : Factor w/ 3 levels \"1\",\"2\",\"3\": 3 3 3 3 3 3 3 3 3 3 ...\n $ haveKids      : logi [1:10691] TRUE TRUE TRUE TRUE TRUE TRUE ...\n $ age           : num [1:10691] 36 36 36 36 36 36 36 36 36 36 ...\n $ educationLevel: Ord.factor w/ 4 levels \"Bachelors\"&lt;\"Graduate\"&lt;..: 3 3 3 3 3 3 3 3 3 3 ...\n $ interestGroup : chr [1:10691] \"H\" \"H\" \"H\" \"H\" ...\n $ joviality     : num [1:10691] 0.00163 0.00163 0.00163 0.00163 0.00163 ...\n $ age_group     : Factor w/ 4 levels \"18-29 yrs\",\"30-39 yrs\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ timestamp     : chr [1:10691] \"2022-03\" \"2022-04\" \"2022-05\" \"2022-06\" ...\n $ Education     : num [1:10691] -76 -38 -38 -38 -38 ...\n $ Food          : num [1:10691] -268 -266 -265 -257 -270 ...\n $ Recreation    : num [1:10691] -349 -219 -383 -466 -1069 ...\n $ Shelter       : num [1:10691] -1110 -555 -555 -555 -555 ...\n $ Wage          : num [1:10691] 11932 8637 9048 9048 8637 ...\n $ RentAdjustment: num [1:10691] NA NA NA NA NA NA NA NA NA NA ...\n\n\nThere are a total of 10,691 rows and 14 variables.\n\n\nIt provides a summary of the variables in the data frame, including their distribution, range, and missing values. This includes measures such as count, mean, standard deviation, minimum, maximum, and quartiles.\n\nHmisc::describe(resident_financial)\n\nresident_financial \n\n 15  Variables      10691  Observations\n--------------------------------------------------------------------------------\nparticipantId \n       n  missing distinct \n   10691        0     1011 \n\nlowest : 0    1    2    3    4   , highest: 1006 1007 1008 1009 1010\n--------------------------------------------------------------------------------\nhouseholdSize \n       n  missing distinct \n   10691        0        3 \n                            \nValue          1     2     3\nFrequency   4044  3629  3018\nProportion 0.378 0.339 0.282\n--------------------------------------------------------------------------------\nhaveKids \n       n  missing distinct \n   10691        0        2 \n                      \nValue      FALSE  TRUE\nFrequency   7673  3018\nProportion 0.718 0.282\n--------------------------------------------------------------------------------\nage \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n   10691        0       43    0.999    39.13     14.3       20       22 \n     .25      .50      .75      .90      .95 \n      29       39       50       56       58 \n\nlowest : 18 19 20 21 22, highest: 56 57 58 59 60\n--------------------------------------------------------------------------------\neducationLevel \n       n  missing distinct \n   10691        0        4 \n                                                                      \nValue                Bachelors            Graduate HighSchoolOrCollege\nFrequency                 2784                2040                5167\nProportion               0.260               0.191               0.483\n                              \nValue                      Low\nFrequency                  700\nProportion               0.065\n--------------------------------------------------------------------------------\ninterestGroup \n       n  missing distinct \n   10691        0       10 \n\nlowest : A B C D E, highest: F G H I J\n                                                                      \nValue          A     B     C     D     E     F     G     H     I     J\nFrequency   1092  1015  1048  1042   864  1151  1131  1123  1042  1183\nProportion 0.102 0.095 0.098 0.097 0.081 0.108 0.106 0.105 0.097 0.111\n--------------------------------------------------------------------------------\njoviality \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n   10691        0     1011        1   0.4686   0.3311   0.0518   0.1038 \n     .25      .50      .75      .90      .95 \n  0.2179   0.4471   0.7008   0.9008   0.9552 \n\nlowest : 0.000204000 0.000265000 0.000985000 0.001365799 0.001626703\nhighest: 0.992601749 0.997604884 0.997670843 0.998644049 0.999233967\n--------------------------------------------------------------------------------\nage_group \n       n  missing distinct \n   10691        0        4 \n                                                  \nValue      18-29 yrs 30-39 yrs 40-50 yrs 51-60 yrs\nFrequency       2825      2587      2814      2465\nProportion     0.264     0.242     0.263     0.231\n--------------------------------------------------------------------------------\ntimestamp \n       n  missing distinct \n   10691        0       12 \n\nlowest : 2022-03 2022-04 2022-05 2022-06 2022-07\nhighest: 2022-10 2022-11 2022-12 2023-01 2023-02\n                                                                          \nValue      2022-03 2022-04 2022-05 2022-06 2022-07 2022-08 2022-09 2022-10\nFrequency     1011     880     880     880     880     880     880     880\nProportion   0.095   0.082   0.082   0.082   0.082   0.082   0.082   0.082\n                                          \nValue      2022-11 2022-12 2023-01 2023-02\nFrequency      880     880     880     880\nProportion   0.082   0.082   0.082   0.082\n--------------------------------------------------------------------------------\nEducation \n       n  missing distinct     Info     Mean      Gmd \n    3018     7673        8    0.937   -51.15    37.56 \n\nlowest : -182.28 -146.40  -91.14  -76.02  -73.20\nhighest:  -76.02  -73.20  -38.01  -25.62  -12.81\n                                                                          \nValue      -182.28 -146.40  -91.14  -76.02  -73.20  -38.01  -25.62  -12.81\nFrequency       57      49     517     122     407    1023      73     770\nProportion   0.019   0.016   0.171   0.040   0.135   0.339   0.024   0.255\n--------------------------------------------------------------------------------\nFood \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n   10691        0     8208        1   -346.4    92.84   -474.0   -452.2 \n     .25      .50      .75      .90      .95 \n  -421.9   -308.5   -283.5   -265.6   -255.9 \n\nlowest : -590.55 -590.32 -590.16 -585.46 -585.29\nhighest:  -37.37  -36.85  -36.66  -34.80  -31.97\n--------------------------------------------------------------------------------\nRecreation \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n    9492     1199     8888        1   -436.5      232   -835.8   -697.9 \n     .25      .50      .75      .90      .95 \n  -533.7   -405.5   -295.1   -202.5   -147.1 \n\nlowest : -1962.06 -1947.79 -1889.53 -1829.60 -1794.38\nhighest:   -11.85   -11.23    -9.98    -6.24    -5.88\n--------------------------------------------------------------------------------\nShelter \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n   10560      131      960        1     -692    310.8  -1301.6  -1014.5 \n     .25      .50      .75      .90      .95 \n  -800.5   -676.3   -455.4   -375.7   -350.2 \n\nlowest : -7385.96 -5998.49 -5781.88 -4223.40 -4037.32\nhighest:  -282.68  -274.43  -265.41  -257.87  -231.70\n--------------------------------------------------------------------------------\nWage \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n   10691        0     4507        1     4265     2446     1778     1993 \n     .25      .50      .75      .90      .95 \n    2546     3614     5172     7360     9149 \n\nlowest :  1600.00  1603.80  1605.80  1606.60  1614.60\nhighest: 18405.33 19012.28 19521.93 21039.15 21334.65\n--------------------------------------------------------------------------------\nRentAdjustment \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n      72    10619       71        1      763    794.6     94.3    111.0 \n     .25      .50      .75      .90      .95 \n   231.1    497.0    848.3   1403.5   2791.2 \n\nlowest :   77.23   88.47   91.48   94.23   94.35\nhighest: 2430.32 3232.28 3436.52 3852.02 4809.28\n--------------------------------------------------------------------------------\n\n\nFrom the output, there are zero missing values across all columns in resident_financial\n\n\n\n\n\n\nTip\n\n\n\nThe describe() function provides summary statistics for numerical variables by default. If we need to include categorical variables as well, it can set the fast = FALSE argument Hmisc::describe(resident_info, fast = FALSE)\nBy setting fast = FALSE, the describe() function will calculate summary statistics for both numerical and categorical variables in the resident_info data frame.\n\n\n\n\nCreating detailed summary table\n\ndf3 &lt;- resident_financial %&gt;% \n  select(-starts_with('Q'), -starts_with('HQ')) %&gt;%\n  mutate_if(is.integer, as.numeric) %&gt;%\n  mutate_if(is.logical, as.numeric)\n\nSummary_Table &lt;- df3 %&gt;% select_if(is.numeric)\n\nprint(dfSummary(Summary_Table, graph.magnif = 0.75), method = 'render')\n\n\n\nData Frame Summary\nSummary_Table\nDimensions: 10691 x 9\n  Duplicates: 41\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\nhaveKids [numeric]\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n7673\n(\n71.8%\n)\n\n\n1\n:\n3018\n(\n28.2%\n)\n\n\n\n\n10691 (100.0%)\n0 (0.0%)\n\n\n2\nage [numeric]\n\n\n\nMean (sd) : 39.1 (12.4)\n\n\nmin ≤ med ≤ max:\n\n\n18 ≤ 39 ≤ 60\n\n\nIQR (CV) : 21 (0.3)\n\n\n\n43 distinct values\n\n10691 (100.0%)\n0 (0.0%)\n\n\n3\njoviality [numeric]\n\n\n\nMean (sd) : 0.5 (0.3)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 0.4 ≤ 1\n\n\nIQR (CV) : 0.5 (0.6)\n\n\n\n1011 distinct values\n\n10691 (100.0%)\n0 (0.0%)\n\n\n4\nEducation [numeric]\n\n\n\nMean (sd) : -51.1 (35.9)\n\n\nmin ≤ med ≤ max:\n\n\n-182.3 ≤ -38 ≤ -12.8\n\n\nIQR (CV) : 60.4 (-0.7)\n\n\n\n8 distinct values\n\n3018 (28.2%)\n7673 (71.8%)\n\n\n5\nFood [numeric]\n\n\n\nMean (sd) : -346.4 (85.2)\n\n\nmin ≤ med ≤ max:\n\n\n-590.6 ≤ -308.5 ≤ -32\n\n\nIQR (CV) : 138.5 (-0.2)\n\n\n\n7944 distinct values\n\n10691 (100.0%)\n0 (0.0%)\n\n\n6\nRecreation [numeric]\n\n\n\nMean (sd) : -436.5 (221.4)\n\n\nmin ≤ med ≤ max:\n\n\n-1962.1 ≤ -405.5 ≤ -5.9\n\n\nIQR (CV) : 238.6 (-0.5)\n\n\n\n8848 distinct values\n\n9492 (88.8%)\n1199 (11.2%)\n\n\n7\nShelter [numeric]\n\n\n\nMean (sd) : -692 (317.9)\n\n\nmin ≤ med ≤ max:\n\n\n-7386 ≤ -676.3 ≤ -231.7\n\n\nIQR (CV) : 345.1 (-0.5)\n\n\n\n960 distinct values\n\n10560 (98.8%)\n131 (1.2%)\n\n\n8\nWage [numeric]\n\n\n\nMean (sd) : 4265.1 (2436.3)\n\n\nmin ≤ med ≤ max:\n\n\n1600 ≤ 3613.9 ≤ 21334.7\n\n\nIQR (CV) : 2625.6 (0.6)\n\n\n\n4483 distinct values\n\n10691 (100.0%)\n0 (0.0%)\n\n\n9\nRentAdjustment [numeric]\n\n\n\nMean (sd) : 763 (903.6)\n\n\nmin ≤ med ≤ max:\n\n\n77.2 ≤ 497 ≤ 4809.3\n\n\nIQR (CV) : 617.2 (1.2)\n\n\n\n71 distinct values\n\n72 (0.7%)\n10619 (99.3%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.2.3)2023-06-18\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\n\nThe dataset contains information on 10,691 participants. The householdSize variable indicates that the majority of households have 1 or 2 members, with proportions of 0.378 and 0.339, respectively.\nThe variable haveKids shows that 28.2% of the participants have kids, while 71.8% do not.\nThe age variable has a mean age of 39.13 years, with a range from 18 to 60. The distribution shows that the majority of participants are between 29 and 50 years old.\nThe educationLevel variable indicates that the highest proportion of participants (48.3%) have a high school or college education, followed by 26% with a bachelor’s degree and 19.1% with a graduate degree.\nThe interestGroup variable represents the interest groups of the participants, with values ranging from A to J. The highest proportion of participants belongs to interest group J (11.1%), followed by groups E (10.8%) and H (10.5%).\nThe joviality variable has a mean joviality score of 0.4686, with a range from 0.000204 to 0.999234. The distribution of joviality scores shows that the majority of participants have scores between 0.2 and 0.7.\nThe dataset spans a time period from March 2022 to February 2023, with equal frequencies of observations in each month.\nThe Education, Food, Recreation, Shelter, and Wage variables represent financial aspects. These variables have varying ranges and distributions, indicating different levels of spending or income for the participants.\nThe RentAdjustment variable, with only 72 observations, indicates adjustments made to rental prices, ranging from 77.23 to 4809.28, with a mean of 763.\n\n\n\n\n\nDoing some Univariate Visualization on all the columns on Unique dataset\n\n\nhouseholdSizeCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nWe are using resident_new table because it has the unique set of data for each participantID.\nThe code chunk creates a bar plot (geom_bar) for the householdSize column using ggplot2. The bars are filled with #69b3a2 color and have black outlines. The plot is given axis labels, a title, and a minimal theme. The plot is then converted to an interactive plotly object\n\n\n\n\n\n\n# Creating a bar plot for householdSize\nplot_household_size &lt;- ggplot(resident_new, aes(x = householdSize)) +\n  geom_bar(fill = \"#69b3a2\", color = \"black\") +\n  labs(x = \"Household Size\", y = \"Count\") +\n  ggtitle(\"Distribution of Household Size\") +\n  theme_minimal()\n\n# Converting the plot to an interactive plotly object\nplotly_household_size &lt;- ggplotly(plot_household_size) %&gt;%\n  layout(\n    title = list(\n      text = \"Distribution of Household Size\",\n      x = 0.5\n    ),\n    xaxis = list(title = \"Household Size\"),\n    yaxis = list(title = \"Count\"),\n    plot_bgcolor = \"#f5f5f5\",\n    paper_bgcolor = \"#f5f5f5\",\n    font = list(color = \"#333333\")\n  )\n\n# Display the interactive plot\nplotly_household_size\n\n\n\n\n\nHaveKidsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nWe are using resident_new table because it has the unique set of data for each participantID.\nThe code chunk creates a bar plot (geom_bar) for the haveKids column using ggplot2. The bars are filled with two different colors (#69b3a2 and #E45756) to represent the categories “No” and “Yes” respectively. The plot is given axis labels, a title, and a minimal theme. The plot is then converted to an interactive plotly object.\n\n\n\n\n\n\n# Creating a bar plot for haveKids\nplot_have_kids &lt;- ggplot(resident_new, aes(x = factor(haveKids))) +\n  geom_bar(fill = c(\"#69b3a2\", \"#E45756\"), color = \"black\") +\n  labs(x = \"Have Kids\", y = \"Count\") +\n  ggtitle(\"Distribution of Having Kids\") +\n  scale_x_discrete(labels = c(\"No\", \"Yes\")) +\n  theme_minimal()\n\n# Converting the plot to an interactive plotly object\nplotly_have_kids &lt;- ggplotly(plot_have_kids) %&gt;%\n  layout(\n    title = list(\n      text = \"Distribution of Having Kids\",\n      x = 0.5\n    ),\n    xaxis = list(title = \"Have Kids\"),\n    yaxis = list(title = \"Count\"),\n    plot_bgcolor = \"#f5f5f5\",\n    paper_bgcolor = \"#f5f5f5\",\n    font = list(color = \"#333333\")\n  )\n\n# Customize the bar colors\nplotly_have_kids &lt;- plotly_have_kids %&gt;%\n  layout(\n    colorway = c(\"#69b3a2\", \"#E45756\")\n  )\n\n# Display the interactive plot\nplotly_have_kids\n\n\n\n\n\nAgeCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nWe are using resident_new table because it has the unique set of data for each participantID.\nThe code chunk creates a histogram (geom_histogram) for the age column using ggplot2. The histogram bars are filled with a light blue color and outlined in black. The plot is given axis labels, a title, and converted to an interactive plotly object\n\n\n\n\n\n\n# Creating a Histogram for age\nplot_age &lt;- ggplot(resident_new, aes(x = age)) +\n  geom_histogram(binwidth = 5, fill = \"lightblue\", color = \"black\") +\n  labs(x = \"Age\", y = \"Count\") +\n  ggtitle(\"Distribution of Age\")\n\nplotly_age &lt;- ggplotly(plot_age) %&gt;%\n  layout(\n    title = \"Interactive Age Distribution\",\n    xaxis = list(title = \"Age\"),\n    yaxis = list(title = \"Count\"),\n    hovermode = \"closest\",\n    showlegend = FALSE\n  ) %&gt;%\n  config(displayModeBar = TRUE)\n\n# Display the interactive plot\nplotly_age\n\n\n\n\n\nEducation & InterestCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nWe are using resident_new table because it has the unique set of data for each participantID. -`The code chunk creates two bar plots using ggplot2 for the columns educationLevel and interestGroup. Each bar represents a category in the respective column, and the bars are filled with colors corresponding to the category. The plots are given axis labels and titles. The ggplot objects are then converted to interactive plotly objects\n\n\n\n\n\n\n# Creating a bar plot for EducationLevel & InterestGroup\nplot_education_level &lt;- ggplot(resident_new, aes(x = educationLevel, fill = educationLevel)) +\n  geom_bar() +\n  labs(x = \"Education Level\", y = \"Count\") +\n  ggtitle(\"Distribution of Education Level\")\n\nplot_interest_group &lt;- ggplot(resident_new, aes(x = interestGroup, fill = interestGroup)) +\n  geom_bar() +\n  labs(x = \"Interest Group\", y = \"Count\") +\n  ggtitle(\"Distribution of Interest Group\")\n\n# Convert plots to interactive plotly objects\nplotly_education_level &lt;- ggplotly(plot_education_level)\nplotly_interest_group &lt;- ggplotly(plot_interest_group)\n\n# Display the interactive plot\nplotly_education_level \nplotly_interest_group\n\n\n\n\n\nJovialityCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nWe are using resident_new table because it has the unique set of data for each participantID.\nThe code chunk creates a dotplot using ggplot2 for the column joviality. Each dot represents a data point in the column, and the dots are stacked vertically with a ratio of 1.2 and a direction of upward. The dots are filled with a light blue color and have a red border.\n\n\n\n\n\n\n# Creating a dot plot using geom_dotplot\nplot_joviality_dot &lt;- ggplot(resident_new, aes(x = joviality)) +\n  geom_dotplot(stackratio = 1.2,stackdir = \"up\",fill = \"#1696d2\", color = 'red',dotsize = .3) +\n  labs(title = \"Joviality\", x = NULL, y = NULL) +\n  theme(axis.text.y = element_blank(), \n        panel.grid.major = element_blank()\n        )\n\n# Display the dot plot\nplot_joviality_dot"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#visualization",
    "href": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#visualization",
    "title": "Take-home Exercise 1",
    "section": "2. Visualization",
    "text": "2. Visualization\n\n2.1 Comparing householdSize with Age-groups\n\nHouseholdsize VS Age_groupCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe above plot uses the columns householdsize and age_group, and understanding the relationship between them by comparing the heights of the bars within each age group, we can observe the relative proportions of different household sizes. For example, for age_group 40-50yrs has more number of residents of household size 1 .\nBelow is small summary of the code\n\nThe count_table is created by counting the occurrences of each combination of age_group and householdSize in the resident_financial dataframe.\nCustom colors are defined using the scale_fill_manual function, providing a vector of color codes (custom_colors) to be used for filling the bars in the plot.\nThe plot is created using ggplot with count_table as the data. The geom_col function is used to create a bar plot with dodged bars for each age_group, with the householdSize determining the fill color.\nAdditional customizations are applied, such as setting the x-axis label, y-axis label, plot title, and theme.\nThe ggplot plot is then converted to an interactive plot using ggplotly, which enables interactive features such as hover tooltips and zooming.\nVarious customizations are applied to the interactive plot, including customizing the hover label appearance, legend labels, and axis labels and tick fonts.\nFinally, the interactive plot is displayed.\n\n\n\n\n\n\n\n# Calculating count for each combination of age_group and householdSize\ncount_table &lt;- resident_financial %&gt;%\n  count(age_group, householdSize)\n\n# Using custom colors\ncustom_colors &lt;- c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\")\n\n# Plotting the columns\np &lt;- ggplot(count_table, aes(x = age_group, y = n, fill = householdSize)) +\n  geom_col(position = \"dodge\", color = \"white\") +\n  scale_fill_manual(values = custom_colors) +\n  labs(x = \"Age Group\", y = \"Count\", fill = \"Household Size\") +\n  ggtitle(\"Distribution of Household Size within Age Groups\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 16, face = \"bold\"))\n\n# Converting ggplot to interactive plot using ggplotly\nplotly_plot &lt;- ggplotly(p)\n\n# Using tooltip labels\nplotly_plot &lt;- plotly_plot %&gt;% \n  layout(hoverlabel = list(bgcolor = \"white\",\n                           font = list(color = \"black\",\n                                       family = \"Arial, sans-serif\"),\n                           align = \"auto\",\n                           namelength = -1,\n                           bordercolor = \"black\"))\n\n# Customizing legend labels\nplotly_plot &lt;- plotly_plot %&gt;% \n  layout(legend = list(\n    title = list(text = \"Household Size\"),\n    font = list(family = \"Arial, sans-serif\", size = 12),\n    bgcolor = \"white\",\n    bordercolor = \"black\",\n    borderwidth = 1\n  ))\n\n# Customizing axis labels and tick font\nplotly_plot &lt;- plotly_plot %&gt;% \n  layout(xaxis = list(title = \"Age Group\", tickfont = list(family = \"Arial, sans-serif\", size = 12)),\n         yaxis = list(title = \"Count of unique resident\", tickfont = list(family = \"Arial, sans-serif\", size = 12)))\n\n# Displaying the interactive plot\nplotly_plot\n\n\n\n\n\n\n2.2 Comparing Education with Age using Boxplot\n\nEducation VS AgeCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk plot a boxplot comparing the age distribution across different education levels. Each box represents the median and quartiles of age for each education level. The fill color represents the education level. The plot provides a visual summary of the age distribution and potential differences between education levels.\n\n\n\n\n\n# Boxplot of Educationlevel and Age\nplotly_plot &lt;- ggplotly(\n  ggplot(data = resident_financial, aes(x = educationLevel, y = age, fill = educationLevel)) + \n    ggtitle(\"Boxplot of Educationlevel VS  Age\") + \n    labs(x = \"Education\", y = \"Age\") +\n    geom_boxplot(alpha = 0.7, col = 'black') + \n    scale_y_continuous(breaks=seq(0 , max(resident_financial[,\"age\"]), 5))\n)\n\n# Customizing the interactive plot\nplotly_plot &lt;- plotly_plot %&gt;%\n  layout(\n    hoverlabel = list(bgcolor = \"white\", font = list(family = \"Arial\", size = 12, color = \"black\")),\n    legend = list(font = list(family = \"Arial\", size = 12, color = \"black\")),\n    xaxis = list(title = \"Race\", tickfont = list(family = \"Arial\", size = 12, color = \"black\")),\n    yaxis = list(title = \"Age\", tickfont = list(family = \"Arial\", size = 12, color = \"black\")),\n    plot_bgcolor = \"white\"\n  )\n\n# Display the interactive plot\nplotly_plot\n\n\n\n\n\n\n2.3 Count of unique participants for each combination of education and haveKids\n\nEducationLevel Vs haveKidsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk makes a stacked bar chart that visually represents the count of unique participants based on their education level and whether they have kids or not.The n_distinct function is then applied to the participantId column to calculate the count of unique participants for each group.The x-axis represents the education levels, the y-axis represents the number of participants, and the fill color indicates whether the participants have kids or not. The chart is faceted by the haveKids variable, allowing for easy comparison between the two groups.By examining the chart, we can identify patterns and trends in participant distribution. For example, 355 participants doesnt have kids who are having education level HighSchoolorCollege , likewise 170 participants have kids who are doing the same edcutionlevel.\n\n\n\n\n\n# Count of unique participants for each combination of educationLevel and haveKids\nparticipant_count &lt;- resident_financial %&gt;%\n  group_by(educationLevel, haveKids) %&gt;%\n  summarise(count = n_distinct(participantId), .groups = \"keep\")\n\n# Creating the stacked bar chart\nbarplot_chart &lt;- ggplot(data = participant_count, aes(x = educationLevel, y = count, fill = haveKids)) +\n  ggtitle(\"Count of Unique Participants by Education Level and Have Kids\") +\n  labs(x = \"Education Level\", y = \"Number of Participants\") +\n  geom_bar(stat = \"identity\", alpha = 0.7, col = 'black') +\n  facet_grid(. ~ haveKids) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nplotly_chart &lt;- ggplotly(barplot_chart)\nplotly_chart\n\n\n\n\n\n\n2.4 Analysis on EducationLevel and Totalwage\n\nCreate Sum_wages table that will have id, EducationLevel, total wage\n\n\nSum_wagesCheck\n\n\n\nsum_wages &lt;- resident_financial %&gt;%\n  group_by(participantId, educationLevel) %&gt;%\n  summarise(total_wages = sum(Wage)) %&gt;%\n  ungroup()\n\n\n\n\n# Display the data table\nDT::datatable(sum_wages, class= \"compact\", filter='top')\n\n\n\n\n\n\n\n\n\n\nViolin Plot- EducationLevel VS TotalWage\n\n\nViolinCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe violin plot shows the spread and density of total wages for each education level category. The width of the violins represents the density, with wider areas indicating higher frequency of data points. The violins are grouped by education level, allowing for easy comparison of wage distributions between different education levels. Overall, the interactive violin plot provides a clear visualization of the distribution of total wages across education levels. It helps identify patterns, trends, and potential differences in wages based on education level. Further analysis can be performed to explore the relationships between education level, total wages, and other relevant variables.\n\n\n\n\n\n# Violin plot between EducationLevel and Totalwage\nviolin_plot &lt;- ggplot(sum_wages, aes(x = educationLevel, y = total_wages, fill = educationLevel)) +\n  geom_violin(scale = \"width\", trim = FALSE) +\n  scale_fill_discrete() +\n  labs(title = \"Total Wages Distribution by Education Level\",\n       x = \"Education Level\",\n       y = \"Total Wages\") +\n  theme_minimal()\n\n# Converting the ggplot object to an interactive plotly object and displaying it\ninteractive_plot &lt;- ggplotly(violin_plot)\n\ninteractive_plot\n\n\n\n\n\nAnova test between EducationLevel and TotalWages\n\n\nAnovaCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe code chunk conducts a non-parametric analysis of variance (ANOVA) test to examine the relationship between education level (independent variable) and total wages (dependent variable).\nThe ANOVA test assesses whether there are statistically significant differences in the mean total wages across different education levels. The p-value is a measure of the strength of evidence against the null hypothesis of no difference in means. In this case, since the p-value is below the significance level of 0.05, we can conclude that there is strong evidence to reject the null hypothesis.\nOverall, the data analysis indicates that education level has a significant effect on total wages.\n\n\n\n\n\n\nset.seed(1234)\n\nggbetweenstats(data = sum_wages,\n               x = educationLevel,\n               y = total_wages,\n               type = \"np\",\n               mean.ci = TRUE,\n               pairwise.comparisons = TRUE,\n               pairwise.display = \"s\",\n               p.adjust.method = \"fdr\",\n               messages = FALSE\n) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n        axis.title.x = element_text(size = 12),\n        axis.title.y = element_text(size = 12),\n        axis.text.x = element_text(size = 10),\n        axis.text.y = element_text(size = 10),\n        strip.text = element_text(size = 12),\n        panel.grid.major = element_line(color = \"lightgray\"),\n        panel.grid.minor = element_blank()\n      \n)\n\n\n\n\n\n\n2.5 Age Group vs Joviality\n\nJoviality vs Age_groupCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe x axis represents the joviality values, while the y axis represents the age groups. The fill and color aesthetics are set to age_group, resulting in the ridgelines being filled and colored based on the different age groups. The density ridgeline plot is created using the geom_density_ridges function, with a specified bandwidth of 0.05 and an alpha value of 0.6 to control the transparency of the ridgelines. The x-axis scale is adjusted using scale_x_continuous to show tick marks with evenly spaced values.From the plot, it seems that Joviality and age_group has not that much in common to analyze.\n\n\n\n\n\n# Density ridge plot between Joviality and age_group\nggplot(resident_financial, aes(x = joviality, y = age_group,fill = age_group,color = age_group)) +\ngeom_density_ridges(bandwidth = .05, alpha = .6) +\nscale_x_continuous( breaks = scales::pretty_breaks(n = 5)) +\nlabs(title = \" Joviality values Across Age Groups\",\n) +\ntheme(legend.position = \"none\",axis.title.y = element_blank(),panel.grid.major = element_blank(),plot.background = element_rect(fill = \"#e763fa\", color = \"#C7BAA7\"),\n  plot.title = element_text(size = 14, face = \"bold\", color = \"#333333\"),  \n) +\ntheme_minimal() -&gt; plot\n# Displaying the plot\nplot\n\n\n\n\n\nAnova test for Jovality vs Age_group\n\n\nAnova testCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe p-value of 0.08 suggests that there is no significant evidence to reject the null hypothesis that there is no difference in Joviality across different age groups. This may indicates that there might be a trend or some degree of association between Joviality and age_group, but it does not reach the level of statistical significance.\nTherefore, based on this analysis, we do not have sufficient evidence to conclude that there is a significant relationship between Joviality and age_group. Further investigations or a larger sample size might be necessary to explore the potential relationship between these variables in more detail.\n\n\n\n\n\n\nset.seed(1234)\n\nggbetweenstats(data = resident_new,\n               x = age_group,\n               y = joviality,\n               type = \"np\",\n               mean.ci = TRUE,\n               pairwise.comparisons = TRUE,\n               pairwise.display = \"s\",\n               p.adjust.method = \"fdr\",\n               messages = FALSE\n) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n        axis.title.x = element_text(size = 12),\n        axis.title.y = element_text(size = 12),\n        axis.text.x = element_text(size = 10),\n        axis.text.y = element_text(size = 10),\n        strip.text = element_text(size = 12),\n        panel.grid.major = element_line(color = \"lightgray\"),\n        panel.grid.minor = element_blank()\n      \n)\n\n\n\n\n\n\n2.6 Relationship of HeatMap on various Coulmns\n\n# Calculate correlation matrix\ncor_matrix &lt;- cor(resident_financial[, c(\"age\", \"joviality\", \"Education\", \"Food\", \"Recreation\", \"Shelter\", \"Wage\", \"RentAdjustment\")])\n\n# Print correlation matrix\nprint(cor_matrix)\n\n                       age   joviality Education       Food Recreation Shelter\nage             1.00000000 -0.07043452        NA  0.0364880         NA      NA\njoviality      -0.07043452  1.00000000        NA -0.4864067         NA      NA\nEducation               NA          NA         1         NA         NA      NA\nFood            0.03648800 -0.48640671        NA  1.0000000         NA      NA\nRecreation              NA          NA        NA         NA          1      NA\nShelter                 NA          NA        NA         NA         NA       1\nWage           -0.02698547 -0.28216492        NA  0.1325984         NA      NA\nRentAdjustment          NA          NA        NA         NA         NA      NA\n                      Wage RentAdjustment\nage            -0.02698547             NA\njoviality      -0.28216492             NA\nEducation               NA             NA\nFood            0.13259837             NA\nRecreation              NA             NA\nShelter                 NA             NA\nWage            1.00000000             NA\nRentAdjustment          NA              1\n\n\n\nHeat MapCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nBased on the correlation analysis conducted, no significant correlations were observed between these variables- Rent Adjustment, Shelter, Recreation, and Education and any of the other variables in the dataset. Therefore, in order to provide a comprehensive overview of the correlations, I have decided not to plot these variables in the correlation heatmap.\nIt is important to note that the lack of observed correlations does not necessarily imply that these variables are unrelated to the others. Other types of relationships or non-linear associations might exist, which could be explored further through additional analysis or modelling techniques.\nFor the variables that were included in the correlation plot, the following correlations were identified:\nAge and Joviality:\n\nThere is a weak negative correlation between age and joviality (-0.070), indicating that as age increases, joviality tends to decrease slightly.\n\nAge and Food:\n\n-There is a weak positive correlation between age and food (0.036), suggesting that as age increases, food consumption tends to increase slightly. - Joviality and Food:\n-   There is a moderate negative correlation between joviality and food (-0.486), indicating that as joviality increases, food consumption tends to decrease.\n\nFood and Wage:\n\nThere is a weak positive correlation between food and wage (0.133), suggesting that as food consumption increases, wage tends to increase slightly. These correlations provide insights into the relationships between these variables and can guide further analysis and decision-making within our project.\n\n\n\n\n\n\n\n# Calculate correlation matrix on realted columns\ncor_matrix &lt;- cor(resident_financial[, c(\"age\", \"joviality\", \"Food\", \"Wage\")])\n\n# Reshaping the correlation matrix to long format\ncor_matrix_long &lt;- melt(cor_matrix)\n\n# Creating a heatmap\nheatmap_plot &lt;- ggplot(data = cor_matrix_long, aes(x = Var2, y = Var1, fill = value)) +\n  geom_tile(color = \"white\", size = 0.2) +\n  scale_fill_gradient(low = \"#4D79FF\", high = \"#FF4D4D\") +\n  labs(x = \"\", y = \"\", title = \"Correlation Matrix\", fill = \"Correlation\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 12),\n        axis.text.x = element_text(size = 12, angle = 90, vjust = 0.5, hjust = 1,face = \"bold\"),\n        axis.text = element_text(size = 12,face = \"bold\"),\n        legend.text = element_text(size = 12),\n        legend.title = element_text(size = 12))\n\n\n# Converting ggplot object to plotly object\nplotly_obj &lt;- ggplotly(heatmap_plot) %&gt;%\n  layout(\n    title = \"Correlation Matrix\",\n    hovermode = \"closest\",\n    xaxis = list(tickfont = list(size = 10)),\n    yaxis = list(tickfont = list(size = 10)),\n    legend = list(font = list(10)),\n    margin = list(l = 80, r = 80, t = 80, b = 80),\n    hoverlabel = list(bgcolor = \"#FFF\", font = list(size = 10))\n  )\n\n# Display the heatmap\nplotly_obj\n\n\n\n\n\n\n2.7 Relationship between EducationLevel and TotalAmount\n\nCalculating Total Amount for each ParticipantID\n\n\nTotal AmountDataTable\n\n\n\ntotal_amount &lt;- resident_financial %&gt;%\n  group_by(participantId, educationLevel) %&gt;%\n  summarise(totalAmount = sum(Education + Shelter + Food + Wage + Recreation, na.rm = TRUE) - sum(RentAdjustment, na.rm = TRUE),\n            .groups = \"drop\")\n\n\n\n\nDT::datatable(total_amount, class= \"compact\", filter='top')\n\n\n\n\n\n\n\n\n\n\nDensity Plot between EducationLevel and TotalAmount\n\n\nDensity PlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe density plot provides insights into the distribution of total savings among different education levels. The x-axis represents the total amount of savings, while the y-axis represents the density of participants at each savings level.\nFrom the plot, it can be observed that individuals with a bachelor’s degree have a higher concentration of savings compared to other education levels. The density curve for the bachelor’s education level peaks at a higher savings amount, indicating that a significant proportion of participants with a bachelor’s degree have accumulated more savings.\nOn the other hand, participants with lower education levels, such as high school or below, exhibit a lower density of savings. The density curve for these education levels shows a peak at lower savings amounts, suggesting that a majority of participants with lower education levels have savings below 50000.\nThis analysis suggests a positive correlation between education level and savings, with higher education levels generally associated with higher savings. It highlights the potential financial benefits of pursuing higher education, as individuals with higher education levels tend to accumulate more savings over time.\n\n\n\n\n\n\n# Creating the Density Plot\nplot &lt;- ggplot(total_amount, aes(x = totalAmount, fill = educationLevel)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Salary Distribution by Education Level\") +\n  scale_x_continuous(\n    breaks = seq(25000, 200000, 25000),  # Setting the range\n    limits = c(25000, 200000)\n  ) +\n  ylab(\"Density\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12),\n    axis.text.x = element_text(size = 10),\n    axis.text.y = element_text(size = 10),\n    legend.position = \"right\"\n  )\n# Plotting the interactive density plot\nplotly_chart &lt;- ggplotly(plot)\n\nplotly_chart"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#limitations-and-recommendations",
    "href": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#limitations-and-recommendations",
    "title": "Take-home Exercise 1",
    "section": "3. Limitations and Recommendations",
    "text": "3. Limitations and Recommendations\n\nLimitations:\n\n\n\n\n\n\n\nNote\n\n\n\n\nLimited variables: The analysis focuses on a specific set of variables and may not capture the full complexity of the relationship between household size and age group. Other relevant variables that could influence the relationship may not have been considered.\nData quality: The analysis assumes that the data used for the plot is accurate and representative. Any data errors, missing values, or biases in the data could impact the validity of the conclusions drawn.\nGeneralization: The findings and conclusions based on the analysis may not be generalizable to a larger population or different contexts. The analysis is specific to the dataset and participants included, and the results may not hold true for other populations or settings.\n\n\n\n\nRecommendations:\n\n\n\n\n\n\n\nNote\n\n\n\n\nInclude additional variables: To gain a more comprehensive understanding of the relationship between household size and age group, it is recommended to consider other relevant variables such as income, occupation, or geographic location. These variables can provide additional insights and help uncover underlying factors influencing the relationship.\nStatistical tests: While visualizations provide initial insights, it is advisable to conduct statistical tests to determine the significance of relationships. Hypothesis testing, regression analysis, or other appropriate statistical methods can provide more robust evidence and quantify the strength of relationships.\nData validation: It is important to ensure the accuracy and quality of the data used for analysis. Conducting data validation checks, addressing missing values, and verifying the representativeness of the dataset can enhance the reliability of the findings.\nConsider diverse samples: To improve generalizability, it is recommended to include a diverse sample of participants from different demographics, socioeconomic backgrounds, and geographical locations. This can help capture variations and identify potential interactions between variables.\nLongitudinal analysis: Analyzing data over time can provide insights into trends and changes in the relationship between household size and age group. Longitudinal analysis can help identify patterns and determine the stability of relationships over time.\nInterpretation caution: When interpreting the findings, it is important to consider the limitations of the analysis and acknowledge potential confounding variables or alternative explanations. Drawing cautious and nuanced conclusions can prevent over generalization and ensure a more accurate understanding of the relationship between household size and age group."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#appendix",
    "href": "Takehome Exercise/Takehome Ex 1/Take-home_Ex01/Takehome1.html#appendix",
    "title": "Take-home Exercise 1",
    "section": "Appendix",
    "text": "Appendix\n\nParticipants Table:\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe Participants table contains information about the participants involved in the study. It provides details such as participant IDs, household size, presence of children, age, education level, primary interest group, and joviality level.\n\nparticipantId (nominal): This column represents the unique ID assigned to each participant. It serves as a unique identifier for each individual.\nhouseholdSize (integer): This column indicates the number of people in the participant’s household. The values can be 1, 2, or 3, representing different household sizes.\nhaveKids (boolean): This column specifies whether there are children living in the participant’s household. The values can be True or False, indicating the presence or absence of children, respectively.\nage (integer): This column records the age of each participant in years at the start of the study. It provides information about the age distribution of the participants.\neducationLevel (string factor): This column represents the participant’s education level. It is categorized into four levels: “Low,” “HighSchoolOrCollege,” “Bachelors,” and “Graduate.” It captures the educational background of the participants.\ninterestGroup (char): This column denotes the participant’s stated primary interest group. It is represented by a single character, ranging from “A” to “J.” Each character corresponds to a specific interest group to which the participant belongs.\njoviality (float): This column contains a numeric value ranging from 0 to 1, indicating the participant’s overall happiness level at the start of the study. It provides an insight into the emotional well-being of the participants.\n\n\n\n\n\nFinancial Journal Table:\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe Financial Journal table contains transactional details of participants’ expenses. It records information such as participant IDs, timestamps, expense categories, and transaction amounts.\n\nparticipantId (integer): This column serves as a unique ID corresponding to the participant affected by the financial transaction. It helps establish a link between the participants and their financial records.\ntimestamp (datetime): This column records the time when the check-in for the expense was logged. It provides a temporal reference for each financial transaction.\ncategory (string factor): This column describes the expense category associated with each transaction. It is categorized into several categories: “Education,” “Food,” “Recreation,” “RentAdjustment,” “Shelter,” and “Wage.” It classifies the type of expense incurred by the participants.\namount (double): This column represents the amount of the transaction for each financial entry. It captures the numerical value of the expense incurred by the participants.\n\n\n\n\nThese two tables, Participants and Financial Journal, provide crucial information about the participants’ demographic details, and financial transactions."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 2/Takehome2.html",
    "href": "Takehome Exercise/Takehome Ex 2/Takehome2.html",
    "title": "\nTakeHome-2\n",
    "section": "",
    "text": "This assignment focuses on the collaboration between FishEye International and the country of Oceanus to combat illegal, unreported, and unregulated (IUU) fishing. FishEye has received import/export data from Oceanus’ marine and fishing industries to identify companies engaged in illegal activities. However, due to incomplete data, FishEye has transformed the trade records into a knowledge graph. The objective is to leverage visual analytics techniques to unveil temporal patterns within the knowledge graph, allowing FishEye to identify entities involved in IUU fishing and understand business relationships. This analysis aims to provide a detailed understanding of patterns for entities and their activities over time."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 2/Takehome2.html#overview",
    "href": "Takehome Exercise/Takehome Ex 2/Takehome2.html#overview",
    "title": "\nTakeHome-2\n",
    "section": "",
    "text": "This assignment focuses on the collaboration between FishEye International and the country of Oceanus to combat illegal, unreported, and unregulated (IUU) fishing. FishEye has received import/export data from Oceanus’ marine and fishing industries to identify companies engaged in illegal activities. However, due to incomplete data, FishEye has transformed the trade records into a knowledge graph. The objective is to leverage visual analytics techniques to unveil temporal patterns within the knowledge graph, allowing FishEye to identify entities involved in IUU fishing and understand business relationships. This analysis aims to provide a detailed understanding of patterns for entities and their activities over time."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 2/Takehome2.html#objective",
    "href": "Takehome Exercise/Takehome Ex 2/Takehome2.html#objective",
    "title": "\nTakeHome-2\n",
    "section": "Objective",
    "text": "Objective\nThe objective of this analysis is to utilize visual analytics techniques to identify temporal patterns for individual entities and between entities in the knowledge graph derived from Oceanus’ trade records. By examining these patterns, FishEye aims to:\n\nUncover Illegal Fishing Entities: Identify companies that engage in IUU fishing practices by tracking their activities over time. This will help FishEye pinpoint entities involved in illegal fishing operations and prioritize enforcement efforts.\nDetect Business Relationship Patterns: By analyzing temporal patterns, FishEye can identify recurring links, collaborations, or changes in business relationships that might indicate illegal activities or attempts to evade detection.\nMonitor Company Behavior: Track the behavior of suspicious entities that may shut down and reemerge under different names. By visualizing temporal patterns, FishEye can compare the activities of companies over time, enabling them to identify potential reoccurrences of illegal fishing practices.\nProtect Marine Species: Use the findings to develop targeted strategies to mitigate the impact of IUU fishing on marine species. Understanding the patterns of illegal activities will help FishEye take proactive measures to protect vulnerable marine species and ecosystems."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 2/Takehome2.html#my-task",
    "href": "Takehome Exercise/Takehome Ex 2/Takehome2.html#my-task",
    "title": "\nTakeHome-2\n",
    "section": "My TASK",
    "text": "My TASK\nUse visual analytics to identify temporal patterns for individual entities and between entities in the knowledge graph FishEye created from trade records. Categorize the types of business relationship patterns you find. Limit your response to 600 words and 6 images."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 2/Takehome2.html#data-preparation",
    "href": "Takehome Exercise/Takehome Ex 2/Takehome2.html#data-preparation",
    "title": "\nTakeHome-2\n",
    "section": "1. Data Preparation",
    "text": "1. Data Preparation\n\n1.1 Install R packages and import dataset\n\n\nA Glimpse into the Code\npacman::p_load(jsonlite, igraph, tidygraph, ggraph,\n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts,knitr,plotly, \n               ggthemes,hrbrthemes,treemap,patchwork, ggiraph,\n               ggstatsplot, summarytools)\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\nThe code chunk uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages used are\n\njsonlite: It is used for working with JSON data in R, providing functions to parse JSON and convert it to data frames.\nigraph : It offers a wide range of graph algorithms and visualization capabilities\ntidygraph: An interface for manipulating and analyzing graphs using the principles of tidy data\nggraph: It allows for creating aesthetically pleasing and customizable graph visualizations.\nvisNetwork: It provides functions to create and customize interactive network plots\nlubridate: It is a package for working with dates and times in R.\nclock: It is a package for working with time zones, providing functions to convert between different time zones and perform various time-related calculations.\nggiraph: used for interactive features such as tooltips, zooming, and panning. It is particularly useful for creating interactive web-based visualizations.\nhrbrthemes: It provides additional themes and styling options\ntreemap: This package offers functions to create treemaps\nplotly: Used for creating interactive web-based graphs.\nggstatsplot: Used for creating graphics with details from statistical tests.\ngraphlayouts: provides various graph layout algorithms for arranging the nodes and edges of a graph in a visually appealing manner.\nknitr: Used for dynamic report generation\npacthwork: Used to combine plots\nggdist: Used for visualising distribution and uncertainty\nggthemes: Provide additional themes for ggplot2\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nrstatix: used for data manipulation, summarization, and group-wise comparisons\nHmisc : used to compute descriptive statistics for a variable in a dataset\nDT : DataTables that create interactive table on html page.\nsummarytools- used for creating summary statistics and tables for data exploration and reporting\nkableExtra- is used for creating tables in various output formats, such as HTML, PDF, or Word documents.\nggplot2- provides a flexible and layered approach to create a wide variety of high-quality static and interactive plots.\nsummarytools- used for creating summary statistics and tables for data exploration and reporting\nAll packages can be found within CRAN.\n\npacman::p_load() function from the pacman package is used in the following code chunk to install and call the libraries of multiple R packages:\n\n\n\n\n\n1.2 Importing data sets\n\nCodeData dictionary\n\n\n\n\nA Glimpse into the Code\nmc2 &lt;- fromJSON(\"data/mc2_challenge_graph.json\")\n\n\n\n\nA Glimpse into the Code\nglimpse(mc2)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 34576 obs. of  4 variables:\n  ..$ shpcountry: chr [1:34576] \"Polarinda\" NA \"Oceanus\" NA ...\n  ..$ rcvcountry: chr [1:34576] \"Oceanus\" NA \"Oceanus\" NA ...\n  ..$ dataset   : chr [1:34576] \"MC2\" \"MC2\" \"MC2\" \"MC2\" ...\n  ..$ id        : chr [1:34576] \"AquaDelight Inc and Son's\" \"BaringoAmerica Marine Ges.m.b.H.\" \"Yu gan  Sea spray GmbH Industrial\" \"FlounderLeska Marine BV\" ...\n $ links     :'data.frame': 5464378 obs. of  9 variables:\n  ..$ arrivaldate     : chr [1:5464378] \"2034-02-12\" \"2034-03-13\" \"2028-02-07\" \"2028-02-23\" ...\n  ..$ hscode          : chr [1:5464378] \"630630\" \"630630\" \"470710\" \"470710\" ...\n  ..$ valueofgoods_omu: num [1:5464378] 141015 141015 NA NA NA ...\n  ..$ volumeteu       : num [1:5464378] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ weightkg        : int [1:5464378] 4780 6125 10855 11250 11165 11290 9000 19490 6865 19065 ...\n  ..$ dataset         : chr [1:5464378] \"MC2\" \"MC2\" \"MC2\" \"MC2\" ...\n  ..$ source          : chr [1:5464378] \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" ...\n  ..$ target          : chr [1:5464378] \"BaringoAmerica Marine Ges.m.b.H.\" \"BaringoAmerica Marine Ges.m.b.H.\" \"-15045\" \"-15045\" ...\n  ..$ valueofgoodsusd : num [1:5464378] NA NA NA NA NA ...\n\n\n\n\nThe dataset consists of a graph in JSON format with 34,552 nodes and 5,464,092 directed edges. The node attributes include the company name, shipping country, receiving country. The edge attributes provide information such as the source and target company names, arrival date, HS code, value of goods in OMU and USD, volume in TEU, weight in kilograms, dataset identifier, and type.\nNODE\n\nid: Name of the company that originated (or received) the shipment\nshpcountry: Country the company most often associated with when shipping\nrcvcountry: Country the company most often associated with when receiving\n\nEDGE\n\nsource: Name of the company that originated the shipment\ntarget: Name of the company that received the shipment\narrivaldate: Date the shipment arrived at port in YYYY-MM-DD format\nhscode: Harmonized System code for the shipment\nvalueofgoods_omu: Customs-declared value of the total shipment in Oceanus Monetary Units (OMU)\nvolumeteu: The volume of the shipment in ‘Twenty-foot equivalent units’\nweightkg: The weight of the shipment in kilograms (if known)\nvalueofgoodsusd: valueofgoods_omu in USD\n\n\n\n\n\n1.2.1 Spliting data into NODEs and EDGEs\nExtract nodes\n\nExtractionSummary StatiticsData Health\n\n\n\n\nA Glimpse into the Code\nMC2_Nodes &lt;- as_tibble(mc2$nodes) %&gt;%\n  select(id, shpcountry, rcvcountry)\nkable(head(MC2_Nodes))\n\n\n\n\n\nid\nshpcountry\nrcvcountry\n\n\n\n\nAquaDelight Inc and Son’s\nPolarinda\nOceanus\n\n\nBaringoAmerica Marine Ges.m.b.H.\nNA\nNA\n\n\nYu gan Sea spray GmbH Industrial\nOceanus\nOceanus\n\n\nFlounderLeska Marine BV\nNA\nNA\n\n\nOlas del Mar Worldwide\nOceanus\nOceanus\n\n\nFrench Crab S.p.A. Worldwide\nKondanovia\nUtoporiana\n\n\n\n\n\n\n\nA Glimpse into the Code\nstr(MC2_Nodes)\n\n\ntibble [34,576 × 3] (S3: tbl_df/tbl/data.frame)\n $ id        : chr [1:34576] \"AquaDelight Inc and Son's\" \"BaringoAmerica Marine Ges.m.b.H.\" \"Yu gan  Sea spray GmbH Industrial\" \"FlounderLeska Marine BV\" ...\n $ shpcountry: chr [1:34576] \"Polarinda\" NA \"Oceanus\" NA ...\n $ rcvcountry: chr [1:34576] \"Oceanus\" NA \"Oceanus\" NA ...\n\n\n\n\n\n\nA Glimpse into the Code\nHmisc::describe(MC2_Nodes)\n\n\nMC2_Nodes \n\n 3  Variables      34576  Observations\n--------------------------------------------------------------------------------\nid \n       n  missing distinct \n   34576        0    34576 \n\nlowest : -1                                      -10                                     -100                                    -1000                                   -10000                                 \nhighest: zūn yú N.V. Transportation              zūn yú Plc Holdings                     zūn yú Submarine Incorporated Logistics ОАО Ltd. Liability Co                   ОАО S.A. de C.V.                       \n--------------------------------------------------------------------------------\nshpcountry \n       n  missing distinct \n   12217    22359      154 \n\nlowest : -22004      -22005      -22007       Francora   Afarivaria \nhighest: Zaloria     Zambalantis Zambarka    Zawalinda   Zimawand   \n--------------------------------------------------------------------------------\nrcvcountry \n       n  missing distinct \n   31667     2909      113 \n\nlowest : -22005      -22014      -22015      Afarisburg  Alverossia \nhighest: Vientoro    Yggdrasonia Zaloria     Zawalinda   Zimawand   \n--------------------------------------------------------------------------------\n\n\n\n\nChecking Missing Values:\n\n\nA Glimpse into the Code\ncolSums(is.na(MC2_Nodes))\n\n\n        id shpcountry rcvcountry \n         0      22359       2909 \n\n\nshpcountry has 22359 missing values, andrcvcountry has 2909 missing values. To do better analysis, all NA values are replaced by “NULL VALUES”.\n\n\nA Glimpse into the Code\n# Assigning NULL VALUES\nMC2_Nodes &lt;- MC2_Nodes %&gt;%\n  replace(is.na(MC2_Nodes), \"NULL VALUES\")\n\n\nChecking Duplicates\n\n\nA Glimpse into the Code\nany(duplicated(MC2_Nodes))\n\n\n[1] FALSE\n\n\nNo Duplicate values here\n\n\n\nExtract edges\n\nExtractionSummary StatiticsData Health\n\n\n\n\nA Glimpse into the Code\nMC2_Edges &lt;- as_tibble(mc2$links) %&gt;%\n  mutate(ArrivalDate = ymd(arrivaldate)) %&gt;%\n  mutate(Year = year(ArrivalDate)) %&gt;%\n  select(source, target, ArrivalDate, Year, hscode,  valueofgoods_omu, \n         volumeteu, weightkg, valueofgoodsusd) %&gt;% \n  distinct()\nkable(head(MC2_Edges))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsource\ntarget\nArrivalDate\nYear\nhscode\nvalueofgoods_omu\nvolumeteu\nweightkg\nvalueofgoodsusd\n\n\n\n\nAquaDelight Inc and Son’s\nBaringoAmerica Marine Ges.m.b.H.\n2034-02-12\n2034\n630630\n141015\n0\n4780\nNA\n\n\nAquaDelight Inc and Son’s\nBaringoAmerica Marine Ges.m.b.H.\n2034-03-13\n2034\n630630\n141015\n0\n6125\nNA\n\n\nAquaDelight Inc and Son’s\n-15045\n2028-02-07\n2028\n470710\nNA\n0\n10855\nNA\n\n\nAquaDelight Inc and Son’s\n-15045\n2028-02-23\n2028\n470710\nNA\n0\n11250\nNA\n\n\nAquaDelight Inc and Son’s\n-15045\n2028-09-11\n2028\n470710\nNA\n0\n11165\nNA\n\n\nAquaDelight Inc and Son’s\n-15045\n2028-10-09\n2028\n470710\nNA\n0\n11290\nNA\n\n\n\n\n\n\n\nA Glimpse into the Code\nstr(MC2_Edges)\n\n\ntibble [5,309,087 × 9] (S3: tbl_df/tbl/data.frame)\n $ source          : chr [1:5309087] \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" ...\n $ target          : chr [1:5309087] \"BaringoAmerica Marine Ges.m.b.H.\" \"BaringoAmerica Marine Ges.m.b.H.\" \"-15045\" \"-15045\" ...\n $ ArrivalDate     : Date[1:5309087], format: \"2034-02-12\" \"2034-03-13\" ...\n $ Year            : num [1:5309087] 2034 2034 2028 2028 2028 ...\n $ hscode          : chr [1:5309087] \"630630\" \"630630\" \"470710\" \"470710\" ...\n $ valueofgoods_omu: num [1:5309087] 141015 141015 NA NA NA ...\n $ volumeteu       : num [1:5309087] 0 0 0 0 0 0 0 0 0 0 ...\n $ weightkg        : int [1:5309087] 4780 6125 10855 11250 11165 11290 9000 19490 6865 19065 ...\n $ valueofgoodsusd : num [1:5309087] NA NA NA NA NA ...\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nmutate() is used two times to create two derived fields.\nymd() of lubridate package is used to covert arrivaldate field from character data type into date data type.\nyear() of lubridate package is used to convert the values in ArrivalDate field into year values.\nselect() is used not only to select the field needed but also to re-organise the sequent of the fields\n\n\n\n\n\n\n\nA Glimpse into the Code\nHmisc::describe(MC2_Edges)\n\n\nMC2_Edges \n\n 9  Variables      5309087  Observations\n--------------------------------------------------------------------------------\nsource \n       n  missing distinct \n 5309087        0    12217 \n\nlowest : -1                                      -10                                     -11                                     -1143                                   -12                                    \nhighest: zūn yú N.V. Transportation              zūn yú Plc Holdings                     zūn yú Submarine Incorporated Logistics ОАО Ltd. Liability Co                   ОАО S.A. de C.V.                       \n--------------------------------------------------------------------------------\ntarget \n       n  missing distinct \n 5309087        0    31691 \n\nlowest : -100                                    -1000                                   -10000                                  -10001                                  -10002                                 \nhighest: zūn yú N.V. Transportation              zūn yú Plc Holdings                     zūn yú Submarine Incorporated Logistics ОАО Ltd. Liability Co                   ОАО S.A. de C.V.                       \n--------------------------------------------------------------------------------\nArrivalDate \n         n    missing   distinct       Info       Mean        Gmd        .05 \n   5309087          0       2556          1 2031-06-04      841.3 2028-05-18 \n       .10        .25        .50        .75        .90        .95 \n2028-09-16 2029-09-17 2031-05-07 2033-02-26 2034-03-21 2034-08-05 \n\nlowest : 2028-01-01 2028-01-02 2028-01-03 2028-01-04 2028-01-05\nhighest: 2034-12-26 2034-12-27 2034-12-28 2034-12-29 2034-12-30\n--------------------------------------------------------------------------------\nYear \n       n  missing distinct     Info     Mean      Gmd \n 5309087        0        7    0.979     2031    2.261 \n\nlowest : 2028 2029 2030 2031 2032, highest: 2030 2031 2032 2033 2034\n                                                           \nValue        2028   2029   2030   2031   2032   2033   2034\nFrequency  757875 810685 831459 744698 723384 752809 688177\nProportion  0.143  0.153  0.157  0.140  0.136  0.142  0.130\n--------------------------------------------------------------------------------\nhscode \n       n  missing distinct \n 5309087        0     4761 \n\nlowest : 100119 100191 100199 100210 100290, highest: 970300 970400 970500 970600 999999\n--------------------------------------------------------------------------------\nvalueofgoods_omu \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     281  5308806      264        1  1665142  2494994    47545    63625 \n     .25      .50      .75      .90      .95 \n  148130   504485  1202560  3040240  6776195 \n\nlowest :     1100     4200     5705     5800    11010\nhighest: 19624925 20546105 22936140 27928330 44744530\n--------------------------------------------------------------------------------\nvolumeteu \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n 4811006   498081      129    0.411    1.509    2.715        0        0 \n     .25      .50      .75      .90      .95 \n       0        0        0        5       10 \n\nlowest :    0    5   10   15   20, highest:  895  920  990 1110 1215\n--------------------------------------------------------------------------------\nweightkg \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n 5309087        0    91532        1    38161    62208       90      400 \n     .25      .50      .75      .90      .95 \n    3115    10660    19845    32180    60345 \n\nlowest :         0         5        10        15        20\nhighest: 388112230 424448920 435781520 493559110 495492485\n--------------------------------------------------------------------------------\nvalueofgoodsusd \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n 2422832  2886255   129037        1   873608  1638260     1200     5505 \n     .25      .50      .75      .90      .95 \n   27420    72805   159045   287245   506185 \n\nlowest :            0            5           10           15           20\nhighest:  27304923345  34889737360 105076265245 223673947970 225833730200\n\n0 (2422645, 1), 2e+09 (69, 0), 4e+09 (58, 0), 6e+09 (35, 0), 8e+09 (2, 0),\n1e+10 (11, 0), 1.2e+10 (2, 0), 1.4e+10 (2, 0), 1.8e+10 (2, 0), 2.2e+10 (1, 0),\n2.8e+10 (1, 0), 3.4e+10 (1, 0), 1.06e+11 (1, 0), 2.24e+11 (1, 0), 2.26e+11 (1,\n0)\n\nFor the frequency table, variable is rounded to the nearest 2e+09\n--------------------------------------------------------------------------------\n\n\n\n\nChecking Missing Values:\n\n\nA Glimpse into the Code\ncolSums(is.na(MC2_Edges))\n\n\n          source           target      ArrivalDate             Year \n               0                0                0                0 \n          hscode valueofgoods_omu        volumeteu         weightkg \n               0          5308806           498081                0 \n valueofgoodsusd \n         2886255 \n\n\nvalueofgoods_omu has too many missing values and there it will be removed. While on other missing values we can check for more details.\n\n\nA Glimpse into the Code\nMC2_Edges &lt;- MC2_Edges %&gt;% select(-valueofgoods_omu)\n\nglimpse(MC2_Edges)\n\n\nRows: 5,309,087\nColumns: 8\n$ source          &lt;chr&gt; \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son'…\n$ target          &lt;chr&gt; \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica Ma…\n$ ArrivalDate     &lt;date&gt; 2034-02-12, 2034-03-13, 2028-02-07, 2028-02-23, 2028-…\n$ Year            &lt;dbl&gt; 2034, 2034, 2028, 2028, 2028, 2028, 2028, 2028, 2028, …\n$ hscode          &lt;chr&gt; \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"470…\n$ volumeteu       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ weightkg        &lt;int&gt; 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, 6…\n$ valueofgoodsusd &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 586…\n\n\n\n\n\n\n\n\n1.3 Data Wrangling\n\n1.3.1 HsCode related to Fishing\nPreparing for the Edges\nOn first observation it can be seen how many unqiue HsCode available and what all we can use related to fishing. There are 4761 Unique Hscode.\n\n\nA Glimpse into the Code\nhscode &lt;- MC2_Edges %&gt;% \n  group_by( hscode) %&gt;% \n   summarise(Weight = n(), .groups = \"drop\")\n\nglimpse(arrange(hscode, desc(Weight)))\n\n\nRows: 4,761\nColumns: 2\n$ hscode &lt;chr&gt; \"306170\", \"950300\", \"870899\", \"611020\", \"940360\", \"304620\", \"16…\n$ Weight &lt;int&gt; 156204, 123262, 108353, 90772, 89764, 87340, 81858, 66209, 6213…\n\n\nAfter understanding the Singapore Trade Classification and Connect2India, it has been discovered that there is a limited range of codes associated with fishing. These codes encompass numbers ranging from 2301-2530, 1603 to 1605, and 30000 to 390000.\n\n\nA Glimpse into the Code\nMC2_Edges$hscode &lt;- as.integer(MC2_Edges$hscode)\n\nEdge1 &lt;- MC2_Edges %&gt;% filter(between(hscode, 160300, 160599))\nEdge2 &lt;- MC2_Edges %&gt;% filter(between(hscode, 230100, 253099))\nEdge3 &lt;- MC2_Edges %&gt;% filter(between(hscode, 300000, 390000))\n\nMC2_Edges &lt;- rbind(Edge1, Edge2, Edge3) %&gt;%\n  distinct()\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nhscode is converted from chr to int format.\nDuplicate records are removed, if any.\n\n\n\n\nCreating a new Aggregated Edge Table that will have source, target, hscode,Year\n\n\n\nA Glimpse into the Code\nMC2_Edges_Aggregated &lt;- MC2_Edges %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup() \n\n\n\n\n\n\n\n\nTip\n\n\n\n\ngroup_by() is used to aggregate values by source, target, hscode, Year.\nsummarise() and n() are used to count the aggregated records.\nfilter() is then used to perform two selections\n\nto select all records whereby source are not equal to target, and\nto select all records whereby the values of their weights field are greater than 1\n\n\n\n\nPreparing for the Nodes - Creating a fresh data table for the nodes in MC2 by utilizing the source and target information from the MC2_edges_aggregated data table. The objective is to guarantee that all the source and target values are incorporated as nodes in the new data table.\n\n\nA Glimpse into the Code\nid1 &lt;- MC2_Edges_Aggregated %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- MC2_Edges_Aggregated %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nMC2_nodes_extracted &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\nA Glimpse into the Code\nMC2_combined &lt;- tbl_graph(nodes = MC2_nodes_extracted,\n                       edges = MC2_Edges_Aggregated,\n                       directed = TRUE)\n\n\n\n\nA Glimpse into the Code\nMC2_combined\n\n\n# A tbl_graph: 11888 nodes and 90919 edges\n#\n# A directed multigraph with 148 components\n#\n# A tibble: 11,888 × 1\n  id                                          \n  &lt;chr&gt;                                       \n1 \" Direct Herring Company Transit\"           \n2 \" Direct LLC Marine biology\"                \n3 \" Direct Limited Liability Company Shipping\"\n4 \" Direct S.A. de C.V.\"                      \n5 \" Direct Shark Oyj Marine sanctuary\"        \n6 \"-15\"                                       \n# ℹ 11,882 more rows\n#\n# A tibble: 90,919 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1  7899 307590  2029       2\n2     1  7899 307590  2030       3\n3     1   140 307590  2030       2\n# ℹ 90,916 more rows\n\n\nThe dataframe ‘MC2_combined’ has 11888 nodes and 90919 edges. It is a directed graph with 148 components.\n\n\n1.3.2 Years Wise Fishing\nPreparing for the Edges\nChecking the Unique number of years\n\n\nA Glimpse into the Code\nsort(unique(MC2_Edges$Year))\n\n\n[1] 2028 2029 2030 2031 2032 2033 2034\n\n\n\n2028202920302031203220332034All\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nAgg_2028_Edges1 &lt;- Edge1 %&gt;%\n  filter(Year == \"2028\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2028_Edges2 &lt;- Edge2 %&gt;%\n  filter(Year == \"2028\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2028_Edges3 &lt;- Edge3 %&gt;%\n  filter(Year == \"2028\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nAgg_2029_Edges1 &lt;- Edge1 %&gt;%\n  filter(Year == \"2029\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2029_Edges2 &lt;- Edge2 %&gt;%\n  filter(Year == \"2029\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2029_Edges3 &lt;- Edge3 %&gt;%\n  filter(Year == \"2029\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nAgg_2030_Edges1 &lt;- Edge1 %&gt;%\n  filter(Year == \"2030\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2030_Edges2 &lt;- Edge2 %&gt;%\n  filter(Year == \"2030\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2030_Edges3 &lt;- Edge3 %&gt;%\n  filter(Year == \"2030\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nAgg_2031_Edges1 &lt;- Edge1 %&gt;%\n  filter(Year == \"2031\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2031_Edges2 &lt;- Edge2 %&gt;%\n  filter(Year == \"2031\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2031_Edges3 &lt;- Edge3 %&gt;%\n  filter(Year == \"2031\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nAgg_2032_Edges1 &lt;- Edge1 %&gt;%\n  filter(Year == \"2032\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2032_Edges2 &lt;- Edge2 %&gt;%\n  filter(Year == \"2032\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2032_Edges3 &lt;- Edge3 %&gt;%\n  filter(Year == \"2032\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nAgg_2033_Edges1 &lt;- Edge1 %&gt;%\n  filter(Year == \"2033\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2033_Edges2 &lt;- Edge2 %&gt;%\n  filter(Year == \"2033\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2033_Edges3 &lt;- Edge3 %&gt;%\n  filter(Year == \"2033\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nAgg_2034_Edges1 &lt;- Edge1 %&gt;%\n  filter(Year == \"2034\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2034_Edges2 &lt;- Edge2 %&gt;%\n  filter(Year == \"2034\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\nA Glimpse into the Code\nAgg_2034_Edges3 &lt;- Edge3 %&gt;%\n  filter(Year == \"2034\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nCombinedEdges1 &lt;- rbind(Agg_2028_Edges1, \n                        Agg_2029_Edges1, \n                        Agg_2030_Edges1,\n                        Agg_2031_Edges1,\n                        Agg_2032_Edges1,\n                        Agg_2033_Edges1,\n                        Agg_2034_Edges1)\n\n\n\n\n\n\nA Glimpse into the Code\nCombinedEdges2 &lt;- rbind(Agg_2028_Edges2, \n                        Agg_2029_Edges2, \n                        Agg_2030_Edges2,\n                        Agg_2031_Edges2,\n                        Agg_2032_Edges2,\n                        Agg_2033_Edges2,\n                        Agg_2034_Edges2)\n\n\n\n\n\n\nA Glimpse into the Code\nCombinedEdges3 &lt;- rbind(Agg_2028_Edges3, \n                        Agg_2029_Edges3, \n                        Agg_2030_Edges3,\n                        Agg_2031_Edges3,\n                        Agg_2032_Edges3,\n                        Agg_2033_Edges3,\n                        Agg_2034_Edges3)\n\n\n\n\n\n\n\n\nPreparing for the Nodes\n\nCreating a fresh data table for the nodes in MC2 by utilizing the source and target information from the MC2_edges_aggregated data table. The objective is to guarantee that all the source and target values are incorporated as nodes in the new data table.\n\n\n2028202920302031203220332034ALL\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2028_Edges1 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2028_Edges1 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2028_Nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2028_Edges2 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2028_Edges2 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2028_Nodes2 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2028_Edges3 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2028_Edges3 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2028_Nodes3 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2029_Edges1 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2029_Edges1 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2029_Nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2029_Edges2 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2029_Edges2 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2029_Nodes2 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2029_Edges3 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2029_Edges3 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2029_Nodes3 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2030_Edges1 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2030_Edges1 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2030_Nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2030_Edges2 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2030_Edges2 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2030_Nodes2 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2030_Edges3 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2030_Edges3 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2030_Nodes3 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2031_Edges1 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2031_Edges1 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2031_Nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2031_Edges2 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2031_Edges2 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2031_Nodes2 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2031_Edges3 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2031_Edges3 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2031_Nodes3 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2032_Edges1 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2032_Edges1 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2032_Nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2032_Edges2 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2032_Edges2 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2032_Nodes2 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2032_Edges3 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2032_Edges3 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2032_Nodes3 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2033_Edges1 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2033_Edges1 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2033_Nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2033_Edges2 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2033_Edges2 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2033_Nodes2 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2033_Edges3 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2033_Edges3 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2033_Nodes3 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2034_Edges1 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2034_Edges1 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2034_Nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2034_Edges2 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2034_Edges2 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2034_Nodes2 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Agg_2034_Edges3 %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Agg_2034_Edges3 %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nAgg_2034_Nodes3 &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nCombinedNodes1 &lt;- rbind(Agg_2028_Nodes1,\n                        Agg_2029_Nodes1,\n                        Agg_2030_Nodes1,\n                        Agg_2031_Nodes1,\n                        Agg_2032_Nodes1,\n                        Agg_2033_Nodes1,\n                        Agg_2034_Nodes1)\n\n\n\n\n\n\nA Glimpse into the Code\nCombinedNodes2 &lt;- rbind(Agg_2028_Nodes2,\n                        Agg_2029_Nodes2,\n                        Agg_2030_Nodes2,\n                        Agg_2031_Nodes2,\n                        Agg_2032_Nodes2,\n                        Agg_2033_Nodes2,\n                        Agg_2034_Nodes2)\n\n\n\n\n\n\nA Glimpse into the Code\nCombinedNodes3 &lt;- rbind(Agg_2028_Nodes3,\n                        Agg_2029_Nodes3,\n                        Agg_2030_Nodes3,\n                        Agg_2031_Nodes3,\n                        Agg_2032_Nodes3,\n                        Agg_2033_Nodes3,\n                        Agg_2034_Nodes3)\n\n\n\n\n\n\n\n\nBuild the Tidygraph data model\n\n2028202920302031203220332034ALL\n\n\n\n\nA Glimpse into the Code\n# 160300-160599\nGraph2028_1 &lt;- tbl_graph(nodes = Agg_2028_Nodes1,\n                       edges = Agg_2028_Edges1,\n                       directed = TRUE) \n\n\n# 230100, 253099\nGraph2028_2 &lt;- tbl_graph(nodes = Agg_2028_Nodes2,\n                       edges = Agg_2028_Edges2,\n                       directed = TRUE) \n\n# 300000-390000\nGraph2028_3 &lt;- tbl_graph(nodes = Agg_2028_Nodes3,\n                       edges = Agg_2028_Edges3,\n                       directed = TRUE) \n\n\n\n\n\n\nA Glimpse into the Code\n# 160300-160599\nGraph2029_1 &lt;- tbl_graph(nodes = Agg_2029_Nodes1,\n                       edges = Agg_2029_Edges1,\n                       directed = TRUE) \n\n\n# 230100, 253099\nGraph2029_2 &lt;- tbl_graph(nodes = Agg_2029_Nodes2,\n                       edges = Agg_2029_Edges2,\n                       directed = TRUE) \n\n# 300000-390000\nGraph2029_3 &lt;- tbl_graph(nodes = Agg_2029_Nodes3,\n                       edges = Agg_2029_Edges3,\n                       directed = TRUE) \n\n\n\n\n\n\nA Glimpse into the Code\n# 160300-160599\nGraph2030_1 &lt;- tbl_graph(nodes = Agg_2030_Nodes1,\n                       edges = Agg_2030_Edges1,\n                       directed = TRUE) \n\n\n# 230100, 253099\nGraph2030_2 &lt;- tbl_graph(nodes = Agg_2030_Nodes2,\n                       edges = Agg_2030_Edges2,\n                       directed = TRUE) \n\n# 300000-390000\nGraph2030_3 &lt;- tbl_graph(nodes = Agg_2030_Nodes3,\n                       edges = Agg_2030_Edges3,\n                       directed = TRUE) \n\n\n\n\n\n\nA Glimpse into the Code\n# 160300-160599\nGraph2031_1 &lt;- tbl_graph(nodes = Agg_2031_Nodes1,\n                       edges = Agg_2031_Edges1,\n                       directed = TRUE) \n\n\n# 230100, 253099\nGraph2031_2 &lt;- tbl_graph(nodes = Agg_2031_Nodes2,\n                       edges = Agg_2031_Edges2,\n                       directed = TRUE) \n\n# 300000-390000\nGraph2031_3 &lt;- tbl_graph(nodes = Agg_2031_Nodes3,\n                       edges = Agg_2031_Edges3,\n                       directed = TRUE) \n\n\n\n\n\n\nA Glimpse into the Code\n# 160300-160599\nGraph2032_1 &lt;- tbl_graph(nodes = Agg_2032_Nodes1,\n                       edges = Agg_2032_Edges1,\n                       directed = TRUE) \n\n\n# 230100, 253099\nGraph2032_2 &lt;- tbl_graph(nodes = Agg_2032_Nodes2,\n                       edges = Agg_2032_Edges2,\n                       directed = TRUE) \n\n# 300000-390000\nGraph2032_3 &lt;- tbl_graph(nodes = Agg_2032_Nodes3,\n                       edges = Agg_2032_Edges3,\n                       directed = TRUE) \n\n\n\n\n\n\nA Glimpse into the Code\n# 160300-160599\nGraph2033_1 &lt;- tbl_graph(nodes = Agg_2033_Nodes1,\n                       edges = Agg_2033_Edges1,\n                       directed = TRUE) \n\n\n# 230100, 253099\nGraph2033_2 &lt;- tbl_graph(nodes = Agg_2033_Nodes2,\n                       edges = Agg_2033_Edges2,\n                       directed = TRUE) \n\n# 300000-390000\nGraph2033_3 &lt;- tbl_graph(nodes = Agg_2033_Nodes3,\n                       edges = Agg_2033_Edges3,\n                       directed = TRUE) \n\n\n\n\n\n\nA Glimpse into the Code\n# 160300-160599\nGraph2034_1 &lt;- tbl_graph(nodes = Agg_2034_Nodes1,\n                       edges = Agg_2034_Edges1,\n                       directed = TRUE) \n\n\n# 230100, 253099\nGraph2034_2 &lt;- tbl_graph(nodes = Agg_2034_Nodes2,\n                       edges = Agg_2034_Edges2,\n                       directed = TRUE) \n\n# 300000-390000\nGraph2034_3 &lt;- tbl_graph(nodes = Agg_2034_Nodes3,\n                       edges = Agg_2034_Edges3,\n                       directed = TRUE) \n\n\n\n\n\n\nA Glimpse into the Code\n# 160300-160599\nGraph_All1 &lt;- tbl_graph(nodes = CombinedNodes1,\n                       edges = CombinedEdges1,\n                       directed = TRUE) \n\n\n# 230100, 253099\nGraph_All2 &lt;- tbl_graph(nodes = CombinedNodes2,\n                       edges = CombinedEdges2,\n                       directed = TRUE) \n\n# 300000-390000\nGraph_All3 &lt;- tbl_graph(nodes = CombinedNodes3,\n                       edges = CombinedEdges3,\n                       directed = TRUE) \n\n\n\n\n\n\n2028202920302031203220332034All\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nGraph2028_1\n\n\n# A tbl_graph: 1507 nodes and 2396 edges\n#\n# A directed acyclic multigraph with 112 components\n#\n# A tibble: 1,507 × 1\n  id                         \n  &lt;chr&gt;                      \n1 1 Ltd. Liability Co        \n2 1 Ltd. Liability Co Cargo  \n3 2 Limited Liability Company\n4 3 Seabass Sp Logistics     \n5 4 GmbH & Co. KG Logistics  \n6 4 S.A. de C.V. Coral Reef  \n# ℹ 1,501 more rows\n#\n# A tibble: 2,396 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   930 160510  2028       4\n2     2   931 160510  2028       2\n3     2   932 160521  2028       4\n# ℹ 2,393 more rows\n\n\nThe dataframe ‘Graph2028_1’ has 1507 nodes and 2396 edges. It is a directed graph with 112 components.\n\n\n\n\nA Glimpse into the Code\nGraph2028_2\n\n\n# A tbl_graph: 309 nodes and 274 edges\n#\n# A directed acyclic multigraph with 58 components\n#\n# A tibble: 309 × 1\n  id                                                \n  &lt;chr&gt;                                             \n1 Adriatic Squid Sagl -                             \n2 Agua Limited Liability Company Transit            \n3 Ancla Azul Limited Liability Company              \n4 Ancla del Este SE                                 \n5 Andhra Pradesh   Limited Liability Company Tilapia\n6 Aqua Ventures Marine life ОАО Export              \n# ℹ 303 more rows\n#\n# A tibble: 274 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   137 250700  2028       2\n2     2   138 230910  2028       2\n3     3   139 230120  2028       3\n# ℹ 271 more rows\n\n\nThe dataframe ‘Graph2028_2’ has 309 nodes and 274 edges. It is a directed graph with 58 components.\n\n\n\n\nA Glimpse into the Code\nGraph2028_3\n\n\n# A tbl_graph: 4081 nodes and 9908 edges\n#\n# A directed acyclic multigraph with 166 components\n#\n# A tibble: 4,081 × 1\n  id                                  \n  &lt;chr&gt;                               \n1 \" Direct Herring Company Transit\"   \n2 \" Direct S.A. de C.V.\"              \n3 \" Direct Shark Oyj Marine sanctuary\"\n4 \"-59\"                               \n5 \"1 AS Marine sanctuary\"             \n6 \"1 Ltd. Liability Co Cargo\"         \n# ℹ 4,075 more rows\n#\n# A tibble: 9,908 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1  2593 304710  2028       2\n2     1  2593 306170  2028       5\n3     1  2594 306170  2028       3\n# ℹ 9,905 more rows\n\n\nThe dataframe ‘Graph2028_1’ has 4081 nodes and 9908 edges. It is a directed graph with 166 components.\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nGraph2029_1\n\n\n# A tbl_graph: 1617 nodes and 2691 edges\n#\n# A directed multigraph with 117 components\n#\n# A tibble: 1,617 × 1\n  id                                          \n  &lt;chr&gt;                                       \n1 \" Direct Limited Liability Company Shipping\"\n2 \" Direct Shark Oyj Marine sanctuary\"        \n3 \"-54\"                                       \n4 \"2 Ltd. Liability Co\"                       \n5 \"3 Logistics Tom yum\"                       \n6 \"4 GmbH & Co. KG Logistics\"                 \n# ℹ 1,611 more rows\n#\n# A tibble: 2,691 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   927 160414  2029       2\n2     2    62 160414  2029       2\n3     2   979 160414  2029       6\n# ℹ 2,688 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2029_2\n\n\n# A tbl_graph: 317 nodes and 315 edges\n#\n# A directed acyclic multigraph with 50 components\n#\n# A tibble: 317 × 1\n  id                                                  \n  &lt;chr&gt;                                               \n1 \" Direct Shark Oyj Marine sanctuary\"                \n2 \"5 Seagull A/S Marine ecology\"                      \n3 \"Amerigo S.A. de C.V.\"                              \n4 \"Ancla Azul Limited Liability Company\"              \n5 \"Ancla del Este SE\"                                 \n6 \"Andhra Pradesh   Limited Liability Company Tilapia\"\n# ℹ 311 more rows\n#\n# A tibble: 315 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   142 230910  2029       2\n2     2    26 230400  2029       3\n3     2    26 230990  2029       2\n# ℹ 312 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2029_3\n\n\n# A tbl_graph: 4098 nodes and 10373 edges\n#\n# A directed acyclic multigraph with 139 components\n#\n# A tibble: 4,098 × 1\n  id                               \n  &lt;chr&gt;                            \n1 \" Direct Herring Company Transit\"\n2 \"-15\"                            \n3 \"-46\"                            \n4 \"-49\"                            \n5 \"1 AS Marine sanctuary\"          \n6 \"1 Ltd. Liability Co Cargo\"      \n# ℹ 4,092 more rows\n#\n# A tibble: 10,373 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1  2582 307590  2029       2\n2     1  2583 306170  2029       2\n3     1  2584 307590  2029       2\n# ℹ 10,370 more rows\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nGraph2030_1\n\n\n# A tbl_graph: 1558 nodes and 2566 edges\n#\n# A directed acyclic multigraph with 97 components\n#\n# A tibble: 1,558 × 1\n  id                                          \n  &lt;chr&gt;                                       \n1 \" Direct Limited Liability Company Shipping\"\n2 \"1 Limited Liability Company Transport\"     \n3 \"1 Oyj Marine conservation\"                 \n4 \"3 Logistics Tom yum\"                       \n5 \"4 Limited Liability Company Marine ecology\"\n6 \"4 S.A. de C.V. Coral Reef\"                 \n# ℹ 1,552 more rows\n#\n# A tibble: 2,566 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   974 160414  2030       3\n2     2   792 160414  2030      12\n3     2   975 160414  2030       2\n# ℹ 2,563 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2030_2\n\n\n# A tbl_graph: 364 nodes and 348 edges\n#\n# A directed acyclic multigraph with 69 components\n#\n# A tibble: 364 × 1\n  id                                        \n  &lt;chr&gt;                                     \n1 1 Ltd. Liability Co                       \n2 4 Limited Liability Company Marine ecology\n3 5 Seagull A/S Marine ecology              \n4 Amerigo S.A. de C.V.                      \n5 Ancla Azul Limited Liability Company      \n6 Ancla Marina AG Marine conservation       \n# ℹ 358 more rows\n#\n# A tibble: 348 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   165 252321  2030       2\n2     2   166 250100  2030       2\n3     3    34 230400  2030       6\n# ℹ 345 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2030_3\n\n\n# A tbl_graph: 4143 nodes and 10109 edges\n#\n# A directed multigraph with 137 components\n#\n# A tibble: 4,143 × 1\n  id                                          \n  &lt;chr&gt;                                       \n1 \" Direct Herring Company Transit\"           \n2 \" Direct Limited Liability Company Shipping\"\n3 \" Direct S.A. de C.V.\"                      \n4 \"1 AS Marine sanctuary\"                     \n5 \"1 Ltd. Liability Co Cargo\"                 \n6 \"2 Limited Liability Company\"               \n# ℹ 4,137 more rows\n#\n# A tibble: 10,109 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1  2604 307590  2030       3\n2     1  2605 307590  2030       2\n3     1   747 306170  2030       2\n# ℹ 10,106 more rows\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nGraph2031_1\n\n\n# A tbl_graph: 1536 nodes and 2498 edges\n#\n# A directed acyclic multigraph with 94 components\n#\n# A tibble: 1,536 × 1\n  id                                   \n  &lt;chr&gt;                                \n1 1 Limited Liability Company Transport\n2 2 Ltd. Liability Co                  \n3 4 S.A. de C.V.                       \n4 4 S.A. de C.V. Coral Reef            \n5 6 Chart Ges.m.b.H. Export            \n6 9 Marine biology Ltd Family          \n# ℹ 1,530 more rows\n#\n# A tibble: 2,498 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   954 160414  2031       2\n2     1   791 160414  2031      21\n3     2   955 160510  2031       6\n# ℹ 2,495 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2031_2\n\n\n# A tbl_graph: 330 nodes and 314 edges\n#\n# A directed acyclic multigraph with 64 components\n#\n# A tibble: 330 × 1\n  id                                     \n  &lt;chr&gt;                                  \n1 \"5 Seagull A/S Marine ecology\"         \n2 \"Adriatic Catch Bonito Ltd Consultants\"\n3 \"Adriatic Tuna Corp Navigation\"        \n4 \"Adriatic Tuna LC Carriers\"            \n5 \"Ancla Azul Limited Liability Company\" \n6 \"Ancla del Este Sp Fish \"              \n# ℹ 324 more rows\n#\n# A tibble: 314 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1    28 230400  2031      30\n2     1    28 230990  2031       3\n3     2    32 230910  2031       2\n# ℹ 311 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2031_3\n\n\n# A tbl_graph: 4027 nodes and 10033 edges\n#\n# A directed acyclic multigraph with 157 components\n#\n# A tibble: 4,027 × 1\n  id                                          \n  &lt;chr&gt;                                       \n1 \" Direct Herring Company Transit\"           \n2 \" Direct Limited Liability Company Shipping\"\n3 \" Direct S.A. de C.V.\"                      \n4 \" Direct Shark Oyj Marine sanctuary\"        \n5 \"1 AS Marine sanctuary\"                     \n6 \"1 Ltd. Liability Co Cargo\"                 \n# ℹ 4,021 more rows\n#\n# A tibble: 10,033 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1  2613 307590  2031       2\n2     1  2614 307590  2031       2\n3     1   731 306170  2031      12\n# ℹ 10,030 more rows\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nGraph2032_1\n\n\n# A tbl_graph: 1610 nodes and 2628 edges\n#\n# A directed acyclic multigraph with 114 components\n#\n# A tibble: 1,610 × 1\n  id                                     \n  &lt;chr&gt;                                  \n1 \" Direct Herring Company Transit\"      \n2 \"1 Limited Liability Company Transport\"\n3 \"1 Ltd. Liability Co\"                  \n4 \"2 S.A. de C.V.\"                       \n5 \"2 Wharf S.A. de C.V. Delivery\"        \n6 \"3 Starfish CJSC Transport\"            \n# ℹ 1,604 more rows\n#\n# A tibble: 2,628 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1  1018 160529  2032       4\n2     2   832 160414  2032      16\n3     3  1019 160414  2032       2\n# ℹ 2,625 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2032_2\n\n\n# A tbl_graph: 323 nodes and 293 edges\n#\n# A directed acyclic multigraph with 64 components\n#\n# A tibble: 323 × 1\n  id                                   \n  &lt;chr&gt;                                \n1 5 Seagull A/S Marine ecology         \n2 Adriatic Catch Bonito Ltd Consultants\n3 Adriatic Tuna Corp Navigation        \n4 Amerigo S.A. de C.V.                 \n5 Ancla Azul Limited Liability Company \n6 Arena del Mar AB                     \n# ℹ 317 more rows\n#\n# A tibble: 293 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1    26 230400  2032      83\n2     1    26 230990  2032       3\n3     2   151 230910  2032       3\n# ℹ 290 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2032_3\n\n\n# A tbl_graph: 4026 nodes and 9870 edges\n#\n# A directed acyclic multigraph with 146 components\n#\n# A tibble: 4,026 × 1\n  id                                          \n  &lt;chr&gt;                                       \n1 \" Direct Herring Company Transit\"           \n2 \" Direct Limited Liability Company Shipping\"\n3 \" Direct S.A. de C.V.\"                      \n4 \"-15\"                                       \n5 \"-28\"                                       \n6 \"-41\"                                       \n# ℹ 4,020 more rows\n#\n# A tibble: 9,870 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1  2605 306170  2032       2\n2     2  2606 330430  2032       3\n3     3  2607 330730  2032       2\n# ℹ 9,867 more rows\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nGraph2033_1\n\n\n# A tbl_graph: 1542 nodes and 2578 edges\n#\n# A directed acyclic multigraph with 102 components\n#\n# A tibble: 1,542 × 1\n  id                                   \n  &lt;chr&gt;                                \n1 1 Limited Liability Company Transport\n2 1 Ltd. Liability Co                  \n3 2 Wharf S.A. de C.V. Delivery        \n4 7 Ltd. Liability Co Express          \n5 9 Limited Liability Company Brothers \n6 9 Marine biology Ltd Family          \n# ℹ 1,536 more rows\n#\n# A tibble: 2,578 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   783 160414  2033      54\n2     2   959 160414  2033       2\n3     3   960 160414  2033       8\n# ℹ 2,575 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2033_2\n\n\n# A tbl_graph: 308 nodes and 292 edges\n#\n# A directed acyclic multigraph with 66 components\n#\n# A tibble: 308 × 1\n  id                                                  \n  &lt;chr&gt;                                               \n1 \"5 Seagull A/S Marine ecology\"                      \n2 \"Amerigo S.A. de C.V.\"                              \n3 \"Ancla Azul Limited Liability Company\"              \n4 \"Ancla del Este Sp Fish \"                           \n5 \"Andhra Pradesh   Limited Liability Company Tilapia\"\n6 \"Angrapa Compass AB Solutions\"                      \n# ℹ 302 more rows\n#\n# A tibble: 292 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1    25 230400  2033      10\n2     2   146 252620  2033       2\n3     2   147 230320  2033       7\n# ℹ 289 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2033_3\n\n\n# A tbl_graph: 4035 nodes and 10497 edges\n#\n# A directed acyclic multigraph with 149 components\n#\n# A tibble: 4,035 × 1\n  id                               \n  &lt;chr&gt;                            \n1 \" Direct Herring Company Transit\"\n2 \" Direct LLC Marine biology\"     \n3 \" Direct S.A. de C.V.\"           \n4 \"-15\"                            \n5 \"1 AS Marine sanctuary\"          \n6 \"1 Ltd. Liability Co Cargo\"      \n# ℹ 4,029 more rows\n#\n# A tibble: 10,497 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1  2585 306170  2033       2\n2     2  1170 303630  2033       2\n3     3  2586 330730  2033      10\n# ℹ 10,494 more rows\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nGraph2034_1\n\n\n# A tbl_graph: 1521 nodes and 2580 edges\n#\n# A directed acyclic multigraph with 107 components\n#\n# A tibble: 1,521 × 1\n  id                                   \n  &lt;chr&gt;                                \n1 -214                                 \n2 -4                                   \n3 1 Limited Liability Company Transport\n4 2 Wharf S.A. de C.V. Delivery        \n5 7 Ltd. Liability Co Express          \n6 9 Limited Liability Company Brothers \n# ℹ 1,515 more rows\n#\n# A tibble: 2,580 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   986 160419  2034       2\n2     2   987 160510  2034       3\n3     3   822 160414  2034      28\n# ℹ 2,577 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2034_2\n\n\n# A tbl_graph: 335 nodes and 345 edges\n#\n# A directed acyclic multigraph with 48 components\n#\n# A tibble: 335 × 1\n  id                                                \n  &lt;chr&gt;                                             \n1 8 Tidal Company Line                              \n2 Ancla Azul Limited Liability Company              \n3 Andhra Pradesh   Limited Liability Company Tilapia\n4 Angrapa Compass AB Solutions                      \n5 Angrapa Ltd. Liability Co Export                  \n6 Aqua Anchor Sagl Marine sanctuary                 \n# ℹ 329 more rows\n#\n# A tibble: 345 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   152 230990  2034       2\n2     2   153 230990  2034       2\n3     3   154 252520  2034       2\n# ℹ 342 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph2034_3\n\n\n# A tbl_graph: 4051 nodes and 10011 edges\n#\n# A directed acyclic multigraph with 176 components\n#\n# A tibble: 4,051 × 1\n  id                                          \n  &lt;chr&gt;                                       \n1 \" Direct Limited Liability Company Shipping\"\n2 \" Direct S.A. de C.V.\"                      \n3 \"-1515\"                                     \n4 \"1 AS Marine sanctuary\"                     \n5 \"1 Limited Liability Company\"               \n6 \"1 Ltd. Liability Co Cargo\"                 \n# ℹ 4,045 more rows\n#\n# A tibble: 10,011 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1  2602 330499  2034       4\n2     2  2513 330730  2034       3\n3     3  2603 301110  2034       4\n# ℹ 10,008 more rows\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\nGraph_All1\n\n\n# A tbl_graph: 10891 nodes and 17937 edges\n#\n# A directed multigraph with 6568 components\n#\n# A tibble: 10,891 × 1\n  id                         \n  &lt;chr&gt;                      \n1 1 Ltd. Liability Co        \n2 1 Ltd. Liability Co Cargo  \n3 2 Limited Liability Company\n4 3 Seabass Sp Logistics     \n5 4 GmbH & Co. KG Logistics  \n6 4 S.A. de C.V. Coral Reef  \n# ℹ 10,885 more rows\n#\n# A tibble: 17,937 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   930 160510  2028       4\n2     2   931 160510  2028       2\n3     2   932 160521  2028       4\n# ℹ 17,934 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph_All2\n\n\n# A tbl_graph: 2286 nodes and 2181 edges\n#\n# A directed multigraph with 1378 components\n#\n# A tibble: 2,286 × 1\n  id                                                \n  &lt;chr&gt;                                             \n1 Adriatic Squid Sagl -                             \n2 Agua Limited Liability Company Transit            \n3 Ancla Azul Limited Liability Company              \n4 Ancla del Este SE                                 \n5 Andhra Pradesh   Limited Liability Company Tilapia\n6 Aqua Ventures Marine life ОАО Export              \n# ℹ 2,280 more rows\n#\n# A tibble: 2,181 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   137 250700  2028       2\n2     2   138 230910  2028       2\n3     3   139 230120  2028       3\n# ℹ 2,178 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nGraph_All2\n\n\n# A tbl_graph: 2286 nodes and 2181 edges\n#\n# A directed multigraph with 1378 components\n#\n# A tibble: 2,286 × 1\n  id                                                \n  &lt;chr&gt;                                             \n1 Adriatic Squid Sagl -                             \n2 Agua Limited Liability Company Transit            \n3 Ancla Azul Limited Liability Company              \n4 Ancla del Este SE                                 \n5 Andhra Pradesh   Limited Liability Company Tilapia\n6 Aqua Ventures Marine life ОАО Export              \n# ℹ 2,280 more rows\n#\n# A tibble: 2,181 × 5\n   from    to hscode  Year weights\n  &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;\n1     1   137 250700  2028       2\n2     2   138 230910  2028       2\n3     3   139 230120  2028       3\n# ℹ 2,178 more rows"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 2/Takehome2.html#visualization",
    "href": "Takehome Exercise/Takehome Ex 2/Takehome2.html#visualization",
    "title": "\nTakeHome-2\n",
    "section": "2. Visualization",
    "text": "2. Visualization\n\n2.1 Relationship Between Company_Shipment and Year\nEvaluating the yearly shipment weights of the top 100 companies is crucial for discerning shipping patterns. We will probe into the average weight per kilogram each year and study the interplay among the source, weight, and year. This exploration will be facilitated through the utilization of heatmaps and network graphs. Such an analysis will allow us to gain deeper insights into the shipping trends and dynamics.\n\nEdgeNode\n\n\n\n\nA Glimpse into the Code\nTop100_Edge &lt;- MC2_Edges_Aggregated %&gt;% \n  arrange(desc(weights)) %&gt;%\n  head(100)\nkable(head(Top100_Edge))\n\n\n\n\n\n\n\n\n\n\n\n\nsource\ntarget\nhscode\nYear\nweights\n\n\n\n\nnián yú Ltd. Corporation\nNiger Bend Limited Liability Company Marine ecology\n304620\n2031\n3471\n\n\nnián yú Ltd. Corporation\nNiger Bend Limited Liability Company Marine ecology\n304620\n2030\n2979\n\n\nnián yú Ltd. Corporation\nCosta de la Felicidad Shipping\n304620\n2029\n2797\n\n\nSea Breezes S.A. de C.V. Freight\nCaracola del Sol Services\n304620\n2031\n2708\n\n\nnián yú Ltd. Corporation\nCosta de la Felicidad Shipping\n304620\n2028\n2473\n\n\nnián yú Ltd. Corporation\nNiger Bend Limited Liability Company Marine ecology\n304620\n2032\n2215\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- Top100_Edge %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- Top100_Edge %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nTop100_Node &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n\n\n\n\n\n\n\nA Glimpse into the Code\nshipment &lt;- Top100_Edge %&gt;%\n         select(Year, weights) %&gt;%\n         group_by(Year) %&gt;%\n         summarise(count=n(),weightkg = sum(weights),kg_per_ship=weightkg/count)\n\np1 &lt;- ggplot(data=shipment, \n            aes(x = Year,\n                y = kg_per_ship)) +\n  geom_bar(stat = \"identity\") +\n  xlab(\"Year\") +\n  ylab(\"Average per Kg\")\n\nggplotly(p1)\n\n\n\n\n\n\nA Glimpse into the Code\n# HeatMap \nheatmap_data &lt;- Top100_Edge %&gt;%\n  group_by(source, Year) %&gt;%\n  summarise(count = n(), .groups = 'drop')\n\nggplot(heatmap_data, aes(x = Year, y = source, fill = count)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"blue\") +\n  labs(x = \"Year\", y = \"Source\", fill = \"Count of Weights\", \n       title = \"Heatmap of Weights Count by Source and Year\")\n\n\n\n\n\nA Glimpse into the Code\n# Network Graph\n\nGraph_Top100 &lt;- tbl_graph(nodes = Top100_Node, edges = Top100_Edge, directed = TRUE)\nggraph(Graph_Top100, layout = \"fr\") + \n  geom_edge_fan(aes(width = weights, colour = factor(Year)), \n                 alpha=0.7, arrow = arrow(length = unit(5, 'mm'))) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(size = 3) + \n  theme_graph() +\n  geom_node_label(aes(label = id), size = 5.5, repel = TRUE, nudge_y = 0.1) +\n  \n  labs(\n    title = \"Network of Top 100 Companies by Weight\")\n\n\n\n\n\nIn this analysis, we visualized a network graph using the MC2 dataset where nodes represent different sources/targets, and the edges between them represent the shipment weights, with the edge thickness indicating the magnitude of weights. The color of the edges denotes different years.\nOur network graph, particularly focusing on the weights, shows the flow of shipments from various sources to targets. The top three sources to targets with the highest shipment weights are as follows:\nNián yú Ltd. Corporation to Niger Bend Limited Liability Company Marine ecology with shipment weights of 3471 and 2979 in years 2031 and 2030, respectively.\nNián yú Ltd. Corporation to Costa de la Felicidad Shipping with shipment weights of 2797 and 2473 in years 2029 and 2028, respectively.\nSea Breezes S.A. de C.V. Freight to Caracola del Sol Services with a shipment weight of 2708 in the year 2031.\nThese insights are critical in understanding the dynamics of shipment weights from different sources to targets over the years.\n\n\n2.2 Degree Centrality (In, Out and Total)\n\n\n\n\n\n\nNote\n\n\n\n\n\n    **In-Degree Centrality:** For each node representing a shipping company , the in-degree centrality measures the number of incoming connections from other nodes. If this network represents the transfer of illegal goods (like illegally caught fish), a high in-degree centrality could suggest that a company is a major receiver of illegal goods. For example, a shipping company with high in-degree centrality might be a significant destination for illegal fish products.\n\n    **Out-Degree Centrality:**  For each node, the out-degree centrality measures the number of outgoing connections to other nodes. In the illegal fishing, a high out-degree centrality could indicate that a company or vessel is a major distributor or source of illegal goods. For instance, a fishing vessel with high out-degree centrality could be a significant source of illegal fishing activities, spreading its illicit catch to many different companies or locations.\n\nTotal Degree Centrality (All Degree Centrality): This measures the total number of connections for each node, both incoming and outgoing. A node with high total degree centrality could be involved in both receiving and distributing illegal goods. This indicate that a shipping company or a fishing vessel plays a central role in the illegal fishing network, both obtaining and dispatching illegal catch.\n\n\n\n\n2028202920302031203220332034ALL\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2028_1_in &lt;- degree(Graph2028_1, mode = \"in\")\nDC_2028_1_out &lt;- degree(Graph2028_1, mode = \"out\")\nDC_2028_1_all &lt;- degree(Graph2028_1, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2028_1$nodes$DC_2028_1_in &lt;- DC_2028_1_in\nGraph2028_1$nodes$DC_2028_1_out &lt;- DC_2028_1_out\nGraph2028_1$nodes$DC_2028_1_all &lt;- DC_2028_1_all\n\n# Creating a graph plot with node size proportional to degree centrality\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2028_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2028_1_in, color = DC_2028_1_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2028\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2028_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2028_1_out, color = DC_2028_1_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2028\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2028_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2028_1_all, color = DC_2028_1_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2028\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nHere’s a summary of what each section of the code does:\n\nCalculate Degree Centrality: The degree() function from the igraph package calculates degree centrality for all nodes in the graph. The mode argument specifies whether to calculate in-degree centrality (mode = “in”), out-degree centrality (mode = “out”), or total degree centrality (mode = “all”).\nAdd Degree Centrality to Node Data: The calculated degree centrality values are added to the node attribute data of Graph2028_1.\nCreate Graph Plots: The ggraph package is used to create plots of the graph, with node size proportional to degree centrality. The geom_edge_link() function adds the edges (connections) between nodes to the plot. The geom_node_point() function adds the nodes to the plot, with the size and color of each node determined by its degree centrality. The scale_color_gradient() function sets the color gradient for the nodes based on their degree centrality values, with lower values in blue and higher values in red. The labs() function sets the title for each plot.\nCreate List of Plots: A list of the three plots is created for easy access and comparison.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe type of goods traded is designated by the Harmonized System (HS) codes, which for the scope of this analysis, falls within the range 160300-160599. This HS code range corresponds to various kinds of prepared or preserved fish, crustaceans, and mollusks.\nIn this analysis, we leverage Degree Centrality, a key measure in network analysis, to identify the most significant nodes (companies) in the network and patterns of transactions in the fishing industry. Degree Centrality is computed in three forms:\n\nIn-Degree Centrality: It measures the number of incoming connections to a node. In this Analysis, a higher In-Degree Centrality indicates that a particular fishing company receives a considerable amount of prepared or preserved seafood. The visual representation uses node sizes to mirror this measure with five levels: 0, 50,100,150,200, where a larger size signifies higher In-Degree Centrality.\nOut-Degree Centrality: This quantifies the number of outgoing connections from a node. In our case, a higher Out-Degree Centrality suggests a company is a prominent sender or supplier of prepared or preserved seafood. The node sizes, varying across four levels: 0, 10,20,30, visually signify this measure, with larger sizes indicating higher Out-Degree Centrality.\nTotal Degree Centrality: This metric, the sum of In-Degree and Out-Degree, provides an overall indication of a node’s connectivity within the network, irrespective of the direction of the edge. A high Total Degree Centrality signifies a company engaged in a significant volume of transactions, both in receiving and dispatching seafood. Nodes are visually depicted with varying sizes based on their Total Degree Centrality across four levels: 50,100,150,200.\n\nIn this we calculate these three forms of Degree Centrality for each node (fishing company) for the year 2028, incorporating this information into the network. The resulting visualization aids in understanding the distribution of these centrality measures across the network.\nThe colors in the visualization represent the Degree Centrality values, shifting from blue (lower centrality) to red (higher centrality). This color-coding provides an effective way to visually identify highly connected nodes in the network, which might serve as critical transaction hubs within the network.\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2028_2_in &lt;- degree(Graph2028_2, mode = \"in\")\nDC_2028_2_out &lt;- degree(Graph2028_2, mode = \"out\")\nDC_2028_2_all &lt;- degree(Graph2028_2, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2028_2$nodes$DC_2028_2_in &lt;- DC_2028_2_in\nGraph2028_2$nodes$DC_2028_2_out &lt;- DC_2028_2_out\nGraph2028_2$nodes$DC_2028_2_all &lt;- DC_2028_2_all\n\n# Creating a graph plot with node size proportional to degree centrality\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2028_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2028_2_in, color = DC_2028_2_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2028\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2028_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2028_2_out, color = DC_2028_2_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2028\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2028_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2028_2_all, color = DC_2028_2_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2028\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe edges between the nodes represent transactions involving specific goods categories, identified by Harmonized System (HS) codes 230100 and 253099 for this analysis. HS Code 230100 refers to flours, meals,fish and pellets of meat or meat offal.\nDegree Centrality is computed in three different forms:\n\nIn-Degree Centrality: Higher In-Degree Centrality indicates that a company receives substantial amounts of the specific goods. For this analysis, the node sizes in the visual representation indicate In-Degree Centrality with five different levels: 0, 5, 10, 15, 20. A larger node size signifies higher In-Degree Centrality.\nOut-Degree Centrality: Higher Out-Degree Centrality indicates that a company is a significant sender or supplier of the specific goods. Node sizes in the visual representation range over five levels: 0, 2.5, 5.0, 7.5, 10. A larger node size indicates higher Out-Degree Centrality.\nTotal Degree Centrality: It provides an overall indication of a node’s connectivity within the network, irrespective of the direction of the edge. A high Total Degree Centrality indicates a company with a significant volume of transactions, both in receiving and sending goods. Nodes sizes in the visual representation represent the Total Degree Centrality and range over four levels: 5, 10, 15, 20.\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2028_3_in &lt;- degree(Graph2028_3, mode = \"in\")\nDC_2028_3_out &lt;- degree(Graph2028_3, mode = \"out\")\nDC_2028_3_all &lt;- degree(Graph2028_3, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2028_3$nodes$DC_2028_3_in &lt;- DC_2028_3_in\nGraph2028_3$nodes$DC_2028_3_out &lt;- DC_2028_3_out\nGraph2028_3$nodes$DC_2028_3_all &lt;- DC_2028_3_all\n\n# Creating a graph plot with node size proportional to degree centrality\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2028_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2028_3_in, color = DC_2028_3_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2028\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2028_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2028_3_out, color = DC_2028_3_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2028\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2028_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.3) +\n  geom_node_point(aes(size = DC_2028_3_all, color = DC_2028_3_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2028\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2029_1_in &lt;- degree(Graph2029_1, mode = \"in\")\nDC_2029_1_out &lt;- degree(Graph2029_1, mode = \"out\")\nDC_2029_1_all &lt;- degree(Graph2029_1, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2029_1$nodes$DC_2029_1_in &lt;- DC_2029_1_in\nGraph2029_1$nodes$DC_2029_1_out &lt;- DC_2029_1_out\nGraph2029_1$nodes$DC_2029_1_all &lt;- DC_2029_1_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2029_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2029_1_in, color = DC_2029_1_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2029\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2029_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2029_1_out, color = DC_2029_1_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2029\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2029_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2029_1_all, color = DC_2029_1_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2029\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2029_2_in &lt;- degree(Graph2029_2, mode = \"in\")\nDC_2029_2_out &lt;- degree(Graph2029_2, mode = \"out\")\nDC_2029_2_all &lt;- degree(Graph2029_2, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2029_2$nodes$DC_2029_2_in &lt;- DC_2029_2_in\nGraph2029_2$nodes$DC_2029_2_out &lt;- DC_2029_2_out\nGraph2029_2$nodes$DC_2029_2_all &lt;- DC_2029_2_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2029_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2029_2_in, color = DC_2029_2_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2029\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2029_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2029_2_out, color = DC_2029_2_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2029\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2029_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2029_2_all, color = DC_2029_2_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2029\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2029_3_in &lt;- degree(Graph2029_3, mode = \"in\")\nDC_2029_3_out &lt;- degree(Graph2029_3, mode = \"out\")\nDC_2029_3_all &lt;- degree(Graph2029_3, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2029_3$nodes$DC_2029_3_in &lt;- DC_2029_3_in\nGraph2029_3$nodes$DC_2029_3_out &lt;- DC_2029_3_out\nGraph2029_3$nodes$DC_2029_3_all &lt;- DC_2029_3_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2029_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2029_3_in, color = DC_2029_3_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2029\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2029_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2029_3_out, color = DC_2029_3_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2029\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2029_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2029_3_all, color = DC_2029_3_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2029\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2030_1_in &lt;- degree(Graph2030_1, mode = \"in\")\nDC_2030_1_out &lt;- degree(Graph2030_1, mode = \"out\")\nDC_2030_1_all &lt;- degree(Graph2030_1, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2030_1$nodes$DC_2030_1_in &lt;- DC_2030_1_in\nGraph2030_1$nodes$DC_2030_1_out &lt;- DC_2030_1_out\nGraph2030_1$nodes$DC_2030_1_all &lt;- DC_2030_1_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2030_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2030_1_in, color = DC_2030_1_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2030\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2030_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2030_1_out, color = DC_2030_1_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2030\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2030_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2030_1_all, color = DC_2030_1_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2030\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2030_2_in &lt;- degree(Graph2030_2, mode = \"in\")\nDC_2030_2_out &lt;- degree(Graph2030_2, mode = \"out\")\nDC_2030_2_all &lt;- degree(Graph2030_2, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2030_2$nodes$DC_2030_2_in &lt;- DC_2030_2_in\nGraph2030_2$nodes$DC_2030_2_out &lt;- DC_2030_2_out\nGraph2030_2$nodes$DC_2030_2_all &lt;- DC_2030_2_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2030_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2030_2_in, color = DC_2030_2_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2030\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2030_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2030_2_out, color = DC_2030_2_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2030\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2030_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2030_2_all, color = DC_2030_2_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2030\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2030_3_in &lt;- degree(Graph2030_3, mode = \"in\")\nDC_2030_3_out &lt;- degree(Graph2030_3, mode = \"out\")\nDC_2030_3_all &lt;- degree(Graph2030_3, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2030_3$nodes$DC_2030_3_in &lt;- DC_2030_3_in\nGraph2030_3$nodes$DC_2030_3_out &lt;- DC_2030_3_out\nGraph2030_3$nodes$DC_2030_3_all &lt;- DC_2030_3_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2030_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2030_3_in, color = DC_2030_3_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2030\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2030_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2030_3_out, color = DC_2030_3_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2030\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2030_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2030_3_all, color = DC_2030_3_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2030\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2031_1_in &lt;- degree(Graph2031_1, mode = \"in\")\nDC_2031_1_out &lt;- degree(Graph2031_1, mode = \"out\")\nDC_2031_1_all &lt;- degree(Graph2031_1, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2031_1$nodes$DC_2031_1_in &lt;- DC_2031_1_in\nGraph2031_1$nodes$DC_2031_1_out &lt;- DC_2031_1_out\nGraph2031_1$nodes$DC_2031_1_all &lt;- DC_2031_1_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2031_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2031_1_in, color = DC_2031_1_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2031\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2031_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2031_1_out, color = DC_2031_1_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2031\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2031_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2031_1_all, color = DC_2031_1_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2031\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2031_2_in &lt;- degree(Graph2031_2, mode = \"in\")\nDC_2031_2_out &lt;- degree(Graph2031_2, mode = \"out\")\nDC_2031_2_all &lt;- degree(Graph2031_2, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2031_2$nodes$DC_2031_2_in &lt;- DC_2031_2_in\nGraph2031_2$nodes$DC_2031_2_out &lt;- DC_2031_2_out\nGraph2031_2$nodes$DC_2031_2_all &lt;- DC_2031_2_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2031_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2031_2_in, color = DC_2031_2_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2031\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2031_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2031_2_out, color = DC_2031_2_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2031\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2031_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2031_2_all, color = DC_2031_2_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2031\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2031_3_in &lt;- degree(Graph2031_3, mode = \"in\")\nDC_2031_3_out &lt;- degree(Graph2031_3, mode = \"out\")\nDC_2031_3_all &lt;- degree(Graph2031_3, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2031_3$nodes$DC_2031_3_in &lt;- DC_2031_3_in\nGraph2031_3$nodes$DC_2031_3_out &lt;- DC_2031_3_out\nGraph2031_3$nodes$DC_2031_3_all &lt;- DC_2031_3_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2031_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2031_3_in, color = DC_2031_3_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2031\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2031_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2031_3_out, color = DC_2031_3_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2031\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2031_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2031_3_all, color = DC_2031_3_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2031\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2032_1_in &lt;- degree(Graph2032_1, mode = \"in\")\nDC_2032_1_out &lt;- degree(Graph2032_1, mode = \"out\")\nDC_2032_1_all &lt;- degree(Graph2032_1, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2032_1$nodes$DC_2032_1_in &lt;- DC_2032_1_in\nGraph2032_1$nodes$DC_2032_1_out &lt;- DC_2032_1_out\nGraph2032_1$nodes$DC_2032_1_all &lt;- DC_2032_1_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2032_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2032_1_in, color = DC_2032_1_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2032\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2032_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2032_1_out, color = DC_2032_1_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2032\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2032_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2032_1_all, color = DC_2032_1_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2032\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2032_2_in &lt;- degree(Graph2032_2, mode = \"in\")\nDC_2032_2_out &lt;- degree(Graph2032_2, mode = \"out\")\nDC_2032_2_all &lt;- degree(Graph2032_2, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2032_2$nodes$DC_2032_2_in &lt;- DC_2032_2_in\nGraph2032_2$nodes$DC_2032_2_out &lt;- DC_2032_2_out\nGraph2032_2$nodes$DC_2032_2_all &lt;- DC_2032_2_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2032_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2032_2_in, color = DC_2032_2_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2032\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2032_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2032_2_out, color = DC_2032_2_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2032\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2032_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2032_2_all, color = DC_2032_2_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2032\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2032_3_in &lt;- degree(Graph2032_3, mode = \"in\")\nDC_2032_3_out &lt;- degree(Graph2032_3, mode = \"out\")\nDC_2032_3_all &lt;- degree(Graph2032_3, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2032_3$nodes$DC_2032_3_in &lt;- DC_2032_3_in\nGraph2032_3$nodes$DC_2032_3_out &lt;- DC_2032_3_out\nGraph2032_3$nodes$DC_2032_3_all &lt;- DC_2032_3_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2032_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2032_3_in, color = DC_2032_3_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2032\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2032_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2032_3_out, color = DC_2032_3_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2032\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2032_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2032_3_all, color = DC_2032_3_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2032\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2033_1_in &lt;- degree(Graph2033_1, mode = \"in\")\nDC_2033_1_out &lt;- degree(Graph2033_1, mode = \"out\")\nDC_2033_1_all &lt;- degree(Graph2033_1, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2033_1$nodes$DC_2033_1_in &lt;- DC_2033_1_in\nGraph2033_1$nodes$DC_2033_1_out &lt;- DC_2033_1_out\nGraph2033_1$nodes$DC_2033_1_all &lt;- DC_2033_1_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2033_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2033_1_in, color = DC_2033_1_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2033\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2033_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2033_1_out, color = DC_2033_1_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2033\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2033_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2033_1_all, color = DC_2033_1_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2033\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2033_2_in &lt;- degree(Graph2033_2, mode = \"in\")\nDC_2033_2_out &lt;- degree(Graph2033_2, mode = \"out\")\nDC_2033_2_all &lt;- degree(Graph2033_2, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2033_2$nodes$DC_2033_2_in &lt;- DC_2033_2_in\nGraph2033_2$nodes$DC_2033_2_out &lt;- DC_2033_2_out\nGraph2033_2$nodes$DC_2033_2_all &lt;- DC_2033_2_all\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2033_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2033_2_in, color = DC_2033_2_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2033\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2033_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2033_2_out, color = DC_2033_2_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2033\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2033_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2033_2_all, color = DC_2033_2_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2033\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2033_3_in &lt;- degree(Graph2033_3, mode = \"in\")\nDC_2033_3_out &lt;- degree(Graph2033_3, mode = \"out\")\nDC_2033_3_all &lt;- degree(Graph2033_3, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2033_3$nodes$DC_2033_3_in &lt;- DC_2033_3_in\nGraph2033_3$nodes$DC_2033_3_out &lt;- DC_2033_3_out\nGraph2033_3$nodes$DC_2033_3_all &lt;- DC_2033_3_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2033_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2033_3_in, color = DC_2033_3_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2033\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2033_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2033_3_out, color = DC_2033_3_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2033\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2033_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2033_3_all, color = DC_2033_3_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2033\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2034_1_in &lt;- degree(Graph2034_1, mode = \"in\")\nDC_2034_1_out &lt;- degree(Graph2034_1, mode = \"out\")\nDC_2034_1_all &lt;- degree(Graph2034_1, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2034_1$nodes$DC_2034_1_in &lt;- DC_2034_1_in\nGraph2034_1$nodes$DC_2034_1_out &lt;- DC_2034_1_out\nGraph2034_1$nodes$DC_2034_1_all &lt;- DC_2034_1_all\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2034_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2034_1_in, color = DC_2034_1_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2034\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2034_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2034_1_out, color = DC_2034_1_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2034\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2034_1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2034_1_all, color = DC_2034_1_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2034\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2034_2_in &lt;- degree(Graph2034_2, mode = \"in\")\nDC_2034_2_out &lt;- degree(Graph2034_2, mode = \"out\")\nDC_2034_2_all &lt;- degree(Graph2034_2, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2034_2$nodes$DC_2034_2_in &lt;- DC_2034_2_in\nGraph2034_2$nodes$DC_2034_2_out &lt;- DC_2034_2_out\nGraph2034_2$nodes$DC_2034_2_all &lt;- DC_2034_2_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2034_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2034_2_in, color = DC_2034_2_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2034\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2034_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2034_2_out, color = DC_2034_2_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2034\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2034_2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2034_2_all, color = DC_2034_2_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2034\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_2034_3_in &lt;- degree(Graph2034_3, mode = \"in\")\nDC_2034_3_out &lt;- degree(Graph2034_3, mode = \"out\")\nDC_2034_3_all &lt;- degree(Graph2034_3, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph2034_3$nodes$DC_2034_3_in &lt;- DC_2034_3_in\nGraph2034_3$nodes$DC_2034_3_out &lt;- DC_2034_3_out\nGraph2034_3$nodes$DC_2034_3_all &lt;- DC_2034_3_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph2034_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2034_3_in, color = DC_2034_3_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for 2034\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph2034_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2034_3_out, color = DC_2034_3_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for 2034\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph2034_3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_2034_3_all, color = DC_2034_3_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for 2034\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\n\n\n160300-160599230100, 253099300000-390000\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_ALL_1_in &lt;- degree(Graph_All1, mode = \"in\")\nDC_ALL_1_out &lt;- degree(Graph_All1, mode = \"out\")\nDC_ALL_1_all &lt;- degree(Graph_All1, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph_All1$nodes$DC_ALL_1_in &lt;- DC_ALL_1_in\nGraph_All1$nodes$DC_ALL_1_out &lt;- DC_ALL_1_out\nGraph_All1$nodes$DC_ALL_1_all &lt;- DC_ALL_1_all\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph_All1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_ALL_1_in, color = DC_ALL_1_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for all Years\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph_All1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_ALL_1_out, color = DC_ALL_1_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for all Years\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph_All1, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_ALL_1_all, color = DC_ALL_1_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for all Years\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_ALL_2_in &lt;- degree(Graph_All2, mode = \"in\")\nDC_ALL_2_out &lt;- degree(Graph_All2, mode = \"out\")\nDC_ALL_2_all &lt;- degree(Graph_All2, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph_All2$nodes$DC_ALL_2_in &lt;- DC_ALL_2_in\nGraph_All2$nodes$DC_ALL_2_out &lt;- DC_ALL_2_out\nGraph_All2$nodes$DC_ALL_2_all &lt;- DC_ALL_2_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph_All2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_ALL_2_in, color = DC_ALL_2_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for all Years\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph_All2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_ALL_2_out, color =DC_ALL_2_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for all Years\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph_All2, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_ALL_2_all, color = DC_ALL_2_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for all Years\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\n# Calculate degree centrality for nodes\nDC_ALL_3_in &lt;- degree(Graph_All3, mode = \"in\")\nDC_ALL_3_out &lt;- degree(Graph_All3, mode = \"out\")\nDC_ALL_3_all &lt;- degree(Graph_All3, mode = \"all\")\n\n# Add degree centrality to the nodes data of the graph\nGraph_All3$nodes$DC_ALL_3_in &lt;- DC_ALL_3_in\nGraph_All3$nodes$DC_ALL_3_out &lt;- DC_ALL_3_out\nGraph_All3$nodes$DC_ALL_3_all &lt;- DC_ALL_3_all\n\n\nplot_list &lt;- list()\nplot_list[[\"In Degree Centrality\"]] &lt;- ggraph(Graph_All3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_ALL_3_in, color = DC_ALL_3_in)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"In Degree Centrality Network for all Years\")\n\nplot_list[[\"Out Degree Centrality\"]] &lt;- ggraph(Graph_All3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_ALL_3_out, color = DC_ALL_3_out)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"Out Degree Centrality Network for all Years\")\n\nplot_list[[\"All Degree Centrality\"]] &lt;- ggraph(Graph_All3, layout = \"fr\") + \n  geom_edge_link(alpha = 0.5) +\n  geom_node_point(aes(size = DC_ALL_3_all, color = DC_ALL_3_all)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  theme_graph() +\n  labs(title = \"All Degree Centrality Network for all Years\")\n\nplot_list\n\n\n$`In Degree Centrality`\n\n\n\n\n\n\n$`Out Degree Centrality`\n\n\n\n\n\n\n$`All Degree Centrality`"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 2/Takehome2.html#recommendations-limitations-and-takeaways",
    "href": "Takehome Exercise/Takehome Ex 2/Takehome2.html#recommendations-limitations-and-takeaways",
    "title": "\nTakeHome-2\n",
    "section": "Recommendations, Limitations and Takeaways",
    "text": "Recommendations, Limitations and Takeaways\nRECOMMENDATIONS - Continuous monitoring of the network can lead to early detection of significant changes in trade patterns. If a company suddenly changes its degree of centrality (either in, out, or total), it may be worth investigating the causes behind such a change.\n\nCompanies with high degree centrality (especially out-degree) can be considered critical nodes in the network. If such companies face disruptions, the impact on the overall network can be significant. Thus, a risk assessment focused on these nodes may be beneficial to ensure the network’s robustness.\n  Delving into trading patterns and shipment weight changes over time could provide additional insights.\nExploring the behavior within communities of companies could be another avenue for detecting IUU activities more efficiently.\n\nLIMITATIONS\n\nThe analysis is based on the transactions of goods under specific HS codes. However, it does not account for other potentially relevant factors such as the companies’ sizes, the actual value of transactions, or the geographical information which could provide additional valuable insights.\nWithout additional contextual information about the nodes (companies) and the nature of the transactions, interpretations and recommendations based on the network structure may have limitations.\nDegree centrality assumes that connections are equally important. In reality, a company’s importance might not just depend on the number of connections it has, but also on the quality of these connections, the value of goods transferred, and its strategic position in the network.\nRapid growth in shipping networks might increase the complexity of tracking and monitoring potential IUU activities.\nWithout concrete indicators, classifying companies as red or green flags for IUU based solely on their degree of import/export activities might be speculative.\n\nKEY TAKEAWAYS\n\nA majority of companies demonstrated low in,out and total degree centrality. This suggests that the networks in this industry might be relatively scattered and possibly disjointed.\nThere has been an observable expansion in the shipping networks over time, visible through an increase in connections and shipment frequency. Monitoring this expansion rate is crucial as sudden spikes could indicate potential illegal, unreported, and unregulated (IUU) activities.\nThe high-import/export companies and their top trading partners could potentially act as strategic points for monitoring and controlling IUU activities in the industry.\nThe sparse and potentially disconnected nature of the network might suggest a lack of centralized control or regulation in the industry."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "FishEye International is a non-profit organization that counters illegal, unreported, and unregulated (IUU) fishing activities. They have recently obtained access to a comprehensive database from an international finance corporation, detailing fishing-related businesses. The database, converted into a knowledge graph, carries valuable information about the companies, their owners, employees, and financial conditions. Traditionally, analysts at FishEye have attempted to uncover business anomalies using standard graph analyses and node-link visualizations. However, the intricate and vast scale of the data has made it challenging to discern the true structure of businesses. Consequently, a more effective visual analytics approach is urgently needed to help identify anomalous companies potentially involved in IUU. This analysis aims to provide a detailed understanding of patterns for entities and their activities over time"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#overview",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#overview",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "FishEye International is a non-profit organization that counters illegal, unreported, and unregulated (IUU) fishing activities. They have recently obtained access to a comprehensive database from an international finance corporation, detailing fishing-related businesses. The database, converted into a knowledge graph, carries valuable information about the companies, their owners, employees, and financial conditions. Traditionally, analysts at FishEye have attempted to uncover business anomalies using standard graph analyses and node-link visualizations. However, the intricate and vast scale of the data has made it challenging to discern the true structure of businesses. Consequently, a more effective visual analytics approach is urgently needed to help identify anomalous companies potentially involved in IUU. This analysis aims to provide a detailed understanding of patterns for entities and their activities over time"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#objective",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#objective",
    "title": "Take-home Exercise 3",
    "section": "Objective",
    "text": "Objective\nThe primary goal of this assignment is to devise a new approach that can efficiently process the large and detailed knowledge graph data to identify anomalies in fishing businesses. This approach should allow us to spot irregular patterns, uncover hidden relationships, and reveal potential IUU-involved companies. By accomplishing this objective, we aim to significantly improve FishEye International’s ability to identify, monitor, and counteract IUU fishing activities."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#my-task",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#my-task",
    "title": "Take-home Exercise 3",
    "section": "My TASK",
    "text": "My TASK\nUse visual analytics to identify anomalies in the business groups present in the knowledge graph. Limit your response to 400 words and 5 images."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#data-preparation",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#data-preparation",
    "title": "Take-home Exercise 3",
    "section": "1. Data Preparation",
    "text": "1. Data Preparation\n\n1.1 Install R packages and import dataset\n\n\nA Glimpse into the Code\npacman::p_load(jsonlite, igraph, tidygraph, ggraph,\n               lubridate, tidyverse, graphlayouts,knitr,plotly, \n               ggthemes,hrbrthemes,treemap,patchwork, ggiraph,\n               ggstatsplot, summarytools, ggforce, \n               skimr, tidytext,wordcloud)\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\nThe code chunk uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages used are\n\njsonlite: It is used for working with JSON data in R, providing functions to parse JSON and convert it to data frames.\nigraph : It offers a wide range of graph algorithms and visualization capabilities\ntidygraph: An interface for manipulating and analyzing graphs using the principles of tidy data\nggraph: It allows for creating aesthetically pleasing and customizable graph visualizations.\nlubridate: It is a package for working with dates and times in R.\nggiraph: used for interactive features such as tooltips, zooming, and panning. It is particularly useful for creating interactive web-based visualizations.\nhrbrthemes: It provides additional themes and styling options\ntreemap: This package offers functions to create treemaps\nplotly: Used for creating interactive web-based graphs.\nggstatsplot: Used for creating graphics with details from statistical tests.\ngraphlayouts: provides various graph layout algorithms for arranging the nodes and edges of a graph in a visually appealing manner.\nknitr: Used for dynamic report generation\nggdist: Used for visualising distribution and uncertainty\nggthemes: Provide additional themes for ggplot2\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nrstatix: used for data manipulation, summarization, and group-wise comparisons\nHmisc : used to compute descriptive statistics for a variable in a dataset\nDT : DataTables that create interactive table on html page.\nsummarytools- used for creating summary statistics and tables for data exploration and reporting\nkableExtra- is used for creating tables in various output formats, such as HTML, PDF, or Word documents.\nggplot2- provides a flexible and layered approach to create a wide variety of high-quality static and interactive plots.\nsummarytools- used for creating summary statistics and tables for data exploration and reporting\nAll packages can be found within CRAN.\n\npacman::p_load() function from the pacman package is used in the following code chunk to install and call the libraries of multiple R packages:\n\n\n\n\n\n1.2 Importing data sets\nIn the code chunk below , fromJSON() of jsonlite package is used to import MC3.json into R environment. The output is called mc3. It is a large list R object.\n\n\nA Glimpse into the Code\nmc3 &lt;- fromJSON(\"data/MC3.json\")\n\n\n\n\n1.3 Extracing Edges\n\nEdgeData ExplorationSummary StatiticsData HealthData DictionaryData Visualization\n\n\n\n\nA Glimpse into the Code\nMC3_Edges &lt;- as_tibble(mc3$links) %&gt;% \n  distinct() %&gt;%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %&gt;%\n  group_by(source, target, type) %&gt;%\n    summarise(weights = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  ungroup()\n\n\n\n\nA Glimpse into the Code\nkable(head(MC3_Edges), format = \"html\", caption = \"EDGES\")\n\n\n\nEDGES\n\n\nsource\ntarget\ntype\nweights\n\n\n\n\n1 AS Marine sanctuary\nChristina Taylor\nCompany Contacts\n1\n\n\n1 AS Marine sanctuary\nDebbie Sanders\nBeneficial Owner\n1\n\n\n1 Ltd. Liability Co Cargo\nAngela Smith\nBeneficial Owner\n1\n\n\n1 S.A. de C.V.\nCatherine Cox\nCompany Contacts\n1\n\n\n1 and Sagl Forwading\nAngela Mendoza\nCompany Contacts\n1\n\n\n1 and Sagl Forwading\nChristopher Watson\nBeneficial Owner\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ndistinct() is used to ensure that there will be no duplicated records.\nmutate() and as.character() are used to convert the field data type from list to character.\ngroup_by() and summarise() are used to count the number of unique links.\nthe filter (source!=target) is to ensure that no record with similar source and target.\n\n\n\n\n\n\n\nA Glimpse into the Code\nskim(MC3_Edges)\n\n\n\nData summary\n\n\nName\nMC3_Edges\n\n\nNumber of rows\n24036\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsource\n0\n1\n6\n700\n0\n12856\n0\n\n\ntarget\n0\n1\n6\n28\n0\n21265\n0\n\n\ntype\n0\n1\n16\n16\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nweights\n0\n1\n1\n0\n1\n1\n1\n1\n1\n▁▁▇▁▁\n\n\n\n\n\n\n\nA Glimpse into the Code\nstr(MC3_Edges)\n\n\ntibble [24,036 × 4] (S3: tbl_df/tbl/data.frame)\n $ source : chr [1:24036] \"1 AS Marine sanctuary\" \"1 AS Marine sanctuary\" \"1 Ltd. Liability Co Cargo\" \"1 S.A. de C.V.\" ...\n $ target : chr [1:24036] \"Christina Taylor\" \"Debbie Sanders\" \"Angela Smith\" \"Catherine Cox\" ...\n $ type   : chr [1:24036] \"Company Contacts\" \"Beneficial Owner\" \"Beneficial Owner\" \"Company Contacts\" ...\n $ weights: int [1:24036] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\nA Glimpse into the Code\nDT::datatable(MC3_Edges, class= \"compact\", filter='top')\n\n\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\nHmisc::describe(MC3_Edges)\n\n\nMC3_Edges \n\n 4  Variables      24036  Observations\n--------------------------------------------------------------------------------\nsource \n       n  missing distinct \n   24036        0    12856 \n\nlowest : 1 and Sagl Forwading        1 AS Marine sanctuary       1 Ltd. Liability Co Cargo   1 S.A. de C.V.              2 Limited Liability Company\nhighest: zūn yú GmbH & Co. KG Creek  zūn yú N.V. Shipping        zūn yú S.A. de C.V.         Zuniga-Young                Zuniga and Sons            \n--------------------------------------------------------------------------------\ntarget \n       n  missing distinct \n   24036        0    21265 \n\nlowest : Aaron Adams   Aaron Adkins  Aaron Allen   Aaron Alvarez Aaron Baker  \nhighest: Zachary York  Zachary Young Zoe Allen     Zoe Marsh     Zoe Smith    \n--------------------------------------------------------------------------------\ntype \n       n  missing distinct \n   24036        0        2 \n                                            \nValue      Beneficial Owner Company Contacts\nFrequency             16792             7244\nProportion            0.699            0.301\n--------------------------------------------------------------------------------\nweights \n       n  missing distinct     Info     Mean      Gmd \n   24036        0        1        0        1        0 \n                \nValue          1\nFrequency  24036\nProportion     1\n--------------------------------------------------------------------------------\n\n\n\n\nChecking Missing Values:\n\n\nA Glimpse into the Code\ncolSums(is.na(MC3_Edges))\n\n\n source  target    type weights \n      0       0       0       0 \n\n\nChecking Duplicates\n\n\nA Glimpse into the Code\nany(duplicated(MC3_Edges))\n\n\n[1] FALSE\n\n\n\n\n\nThe dataset comprises of an undirected multi-graph with 27,622 nodes and 24,038 edges.\nIt contains 7,794 connected components.\nThe graph is undirected, implying that relationships or interactions do not have a specific direction or order. In other words, if there is a connection between two nodes, it applies both ways.\n\nEdge Attributes:\n\ntype: This attribute represents the type or nature of the relationship or interaction between the nodes connected by the edge.\nsource: This is the ID of the source node. It identifies where the relationship or interaction originates from in the network.\ntarget: This is the ID of the target node. It identifies where the relationship or interaction is directed towards in the network.\nrole: This provides a more specific classification of the relationship or interaction represented by the edge, like beneficial owner or company contacts.\n\n\n\n\n\nA Glimpse into the Code\nMC3_Edges_count &lt;- MC3_Edges %&gt;%\n  group_by(type) %&gt;%\n  summarise(n = n())\n\n\np &lt;- ggplot(data = MC3_Edges_count, aes(x = type, y = n, fill = type)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  geom_text(aes(label = n), vjust = -0.5) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_minimal() +\n  theme(plot.background = element_rect(fill = \"seashell\"),\n        panel.grid.major = element_line(color = \"grey80\"),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\",\n        text = element_text(size = 12, face = \"bold\"),\n        plot.title = element_text(hjust = 0.5)) +\n  labs(x = \"Type\", y = \"Count\", fill = \"Type\",\n       title = \"Distribution of Edge Types\")\n\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\n1.3 Extracting Nodes\n\nNodeData ExplorationSummary StatiticsData HealthData Dictionary\n\n\n\n\nA Glimpse into the Code\nMC3_Nodes &lt;- as_tibble(mc3$nodes) %&gt;%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %&gt;%\n  select(id, country, type, revenue_omu, product_services)\n\n\n\n\nA Glimpse into the Code\nkable(head(MC3_Nodes), format = \"html\", caption = \"NODES\")\n\n\n\nNODES\n\n\nid\ncountry\ntype\nrevenue_omu\nproduct_services\n\n\n\n\nJones LLC\nZH\nCompany\n310612303\nAutomobiles\n\n\nColeman, Hall and Lopez\nZH\nCompany\n162734684\nPassenger cars, trucks, vans, and buses\n\n\nAqua Advancements Sashimi SE Express\nOceanus\nCompany\n115004667\nHolding firm whose subsidiaries are engaged in the businesses of refining and chemicals, process and pollution control equipment, minerals, fertilizers, polymers and fibers, commodity trading and services, forest and consumer products, and ranching\n\n\nMakumba Ltd. Liability Co\nUtoporiana\nCompany\n90986413\nCar service, car parts and accessories, automotive technology, diagnostics for repair shops, antilock braking and fuel-injection systems, auto electronics, starters, and alternators; Home (power tools for DIY enthusiasts, garden tools, household appliances, heating and warm water); and industry and trade (communication services, power tools for professional, sensors and foundry - MEMS, security systems, packaging technology)\n\n\nTaylor, Taylor and Farrell\nZH\nCompany\n81466667\nFully electric vehicles (EVs) and electric vehicle powertrain components\n\n\nHarmon, Edwards and Bates\nZH\nCompany\n75070435\nDiscount supermarket; Variety of food and non-food products\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nmutate() and as.character() are used to convert the field data type from list to character.\nTo convert revenue_omu from list data type to numeric data type, we need to convert the values into character first by using as.character(). Then, as.numeric() will be used to convert them into numeric data type.\nselect() is used to re-organise the order of the fields.\n\n\n\n\n\n\n\nA Glimpse into the Code\nskim(MC3_Nodes)\n\n\n\nData summary\n\n\nName\nMC3_Nodes\n\n\nNumber of rows\n27622\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nid\n0\n1\n6\n64\n0\n22929\n0\n\n\ncountry\n0\n1\n2\n15\n0\n100\n0\n\n\ntype\n0\n1\n7\n16\n0\n3\n0\n\n\nproduct_services\n0\n1\n4\n1737\n0\n3244\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrevenue_omu\n21515\n0.22\n1822155\n18184433\n3652.23\n7676.36\n16210.68\n48327.66\n310612303\n▇▁▁▁▁\n\n\n\n\n\n\n\nA Glimpse into the Code\nstr(MC3_Nodes)\n\n\ntibble [27,622 × 5] (S3: tbl_df/tbl/data.frame)\n $ id              : chr [1:27622] \"Jones LLC\" \"Coleman, Hall and Lopez\" \"Aqua Advancements Sashimi SE Express\" \"Makumba Ltd. Liability Co\" ...\n $ country         : chr [1:27622] \"ZH\" \"ZH\" \"Oceanus\" \"Utoporiana\" ...\n $ type            : chr [1:27622] \"Company\" \"Company\" \"Company\" \"Company\" ...\n $ revenue_omu     : num [1:27622] 3.11e+08 1.63e+08 1.15e+08 9.10e+07 8.15e+07 ...\n $ product_services: chr [1:27622] \"Automobiles\" \"Passenger cars, trucks, vans, and buses\" \"Holding firm whose subsidiaries are engaged in the businesses of refining and chemicals, process and pollution \"| __truncated__ \"Car service, car parts and accessories, automotive technology, diagnostics for repair shops, antilock braking a\"| __truncated__ ...\n\n\n\n\nA Glimpse into the Code\nDT::datatable(MC3_Nodes, class= \"compact\", filter='top')\n\n\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\nHmisc::describe(MC3_Nodes)\n\n\nMC3_Nodes \n\n 5  Variables      27622  Observations\n--------------------------------------------------------------------------------\nid \n       n  missing distinct \n   27622        0    22929 \n\nlowest : 1 and Sagl Forwading          1 AS Marine sanctuary         1 Eel Corporation Transport   1 Ltd. Corporation Transport  1 Ltd. Liability Co          \nhighest: Zuniga Inc                    Zuniga Ltd                    Zuniga PLC                    Zuniga, Burgess and Davenport Zuniga, Logan and Newton     \n--------------------------------------------------------------------------------\ncountry \n       n  missing distinct \n   27622        0      100 \n\nlowest : Afarivaria      Alverossia      Alverovia       Andenovia       Anderia del Mar\nhighest: Wysterion       Yggdrasonia     Zambarka        Zawalinda       ZH             \n--------------------------------------------------------------------------------\ntype \n       n  missing distinct \n   27622        0        3 \n                                                             \nValue      Beneficial Owner          Company Company Contacts\nFrequency             11949             8639             7034\nProportion            0.433            0.313            0.255\n--------------------------------------------------------------------------------\nrevenue_omu \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n    6107    21515     4637        1  1822155  3574819     4915     5243 \n     .25      .50      .75      .90      .95 \n    7676    16211    48328   190919   612716 \n\nlowest : 3.652227e+03 4.657797e+03 4.660665e+03 4.666673e+03 4.666703e+03\nhighest: 2.914265e+08 2.929701e+08 3.049959e+08 3.082496e+08 3.106123e+08\n--------------------------------------------------------------------------------\nproduct_services \n       n  missing distinct \n   27622        0     3244 \n\nlowest : (Italian) peeled tomatoes, legumes, vegetables, fruits and canned mushrooms                                                                                                                                                         100 percent Spanish olives; peppers, green, black, and manzanilla stuffed olives; anchovies-stuffed olives; and black olives; Olives recipes                                                                                        2 or 3-piece containers, twist off caps, easy opening and traditional caps; Cutting; varnishing and metal plate lithography                                                                                                         8 Cement Mixer Units, Ocean Freight, Air Freight, Project Logistics, Continental Container Line CCL, Atlantic Pacific Container line APL, Project Arabia Line PAL source: freelance researcher                                      A chemical science firm with a focus on the development of high purity, high performance products and services                                                                                                                     \nhighest: Young soybeans in pods; and spring rolls includes shrimp mini spring rolls with shiitake mushroom, vegetable mini spring rolls with shiitake mushroom, and all natural pre-fried vegetable mini spring rolls with shiitake mushroom Zinc and aluminum die cast hardware and components                                                                                                                                                                                  Zinc and aluminum die cast parts                                                                                                                                                                                                    Zinc metal                                                                                                                                                                                                                          Zumba clothing and accessories                                                                                                                                                                                                     \n--------------------------------------------------------------------------------\n\n\n\n\nChecking Missing Values:\n\n\nA Glimpse into the Code\ncolSums(is.na(MC3_Nodes))\n\n\n              id          country             type      revenue_omu \n               0                0                0            21515 \nproduct_services \n               0 \n\n\nChecking Duplicates\n\n\nA Glimpse into the Code\nany(duplicated(MC3_Nodes))\n\n\n[1] TRUE\n\n\n\n\n\nThe dataset comprises of an undirected multi-graph with 27,622 nodes and 24,038 edges.\nIt contains 7,794 connected components.\nThe graph is undirected, implying that relationships or interactions do not have a specific direction or order. In other words, if there is a connection between two nodes, it applies both ways.\n\nNode Attributes:\n\ntype: The classification or category of the node. This can indicate the nature of the entity, such as company, owner, or worker.\ncountry: This attribute represents the country associated with the node. This can be either a full country name or a two-letter country code.\nproduct_services: This provides a description of the products or services associated with the node. This can help in understanding the node’s role in the network.\nrevenue_omu: This is the operating revenue of the node in Oceanus Monetary Units (OMU). It gives a measure of the financial size or activity of the node.\nid: This is the unique identifier of the node. This ID is also the name of the entity it represents.\nrole: This is a subset of the “type” attribute, providing more detailed classification of the node. It includes roles like beneficial owner or company contacts.\n\n#3 Data Visualization\n\n\nA Glimpse into the Code\nMC3_Nodes_count &lt;- MC3_Nodes %&gt;%\n  group_by(type) %&gt;%\n  summarise(n = n())\n\n\np &lt;- ggplot(data = MC3_Nodes_count, aes(x = type, y = n, fill = type)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  geom_text(aes(label = n), vjust = -0.5) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_minimal() +\n  theme(plot.background = element_rect(fill = \"seashell\"),\n        panel.grid.major = element_line(color = \"grey80\"),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\",\n        text = element_text(size = 12, face = \"bold\"),\n        plot.title = element_text(hjust = 0.5)) +\n  labs(x = \"Type\", y = \"Count\", fill = \"Type\",\n       title = \"Distribution of Edge Types\")\n\nggplotly(p)"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#visualization",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#visualization",
    "title": "Take-home Exercise 3",
    "section": "2. Visualization",
    "text": "2. Visualization\n\n2.1 Top 10 Countries with Highest revenue\n\n\nA Glimpse into the Code\n# Group the data by country and calculate the total revenue\ntop_countries &lt;- MC3_Nodes %&gt;%\n  group_by(country) %&gt;%\n  summarise(total_revenue = sum(revenue_omu, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_revenue)) %&gt;%\n  head(10)\n\n# Plot the top 10 countries by total revenue\np &lt;- ggplot(data = top_countries, aes(x = reorder(country, -total_revenue), y = total_revenue)) +\n  geom_bar(stat = \"identity\") +\n  #geom_text(aes(label = round(total_revenue)), vjust = -0.5) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_minimal() +\n  theme(plot.background = element_rect(fill = \"seashell\"),\n        panel.grid.major = element_line(color = \"grey80\"),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\",\n        text = element_text(size = 12, face = \"bold\"),\n        plot.title = element_text(hjust = 0.5)) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(x = \"Country\", y = \"Total Revenue (OMU)\", fill = \"Country\",\n       title = \"Top 10 Countries by Total Revenue\")\n\n# Convert ggplot object to a plotly object for interactivity\np_interactive &lt;- ggplotly(p)\n\np_interactive"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#number-of-edges-connections-per-node",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#number-of-edges-connections-per-node",
    "title": "Take-home Exercise 3",
    "section": "2.2 Number of Edges (connections) per Node",
    "text": "2.2 Number of Edges (connections) per Node\n\n\nA Glimpse into the Code\n# fuction from igraph-&gt; graph_from_data_frame\ng &lt;- graph_from_data_frame(MC3_Edges, directed = FALSE)\n\n# Calculation of  degrees\nnode_degrees &lt;- degree(g)\n\n# Converting to dataframe\ndf_degrees &lt;- data.frame(node = names(node_degrees), degree = node_degrees)\n\n# Histogram\np &lt;- ggplot(df_degrees, aes(x = degree)) +\n  geom_histogram(binwidth = 1, fill = \"steelblue\", color = \"white\") +\n  xlim(0, 6) +\n  theme_minimal() +\n  labs(x = \"Degree\", y = \"Count\", title = \"Distribution of Node Degrees\")\n\ngp &lt;- ggplotly(p)\n\ngp\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe majority of the nodes in the network graph have a degree of 1. This means that most entities in the network only have one connection with other entities. A count of 29,229 signifies a substantial proportion of the total nodes.\nAs the degree increases, the number of nodes that hold that degree decreases substantially. This trend signifies that it’s less common for entities to have multiple connections in the network. Nodes with a degree of 2 are 2,526. This number is significantly less than those with a degree of 1, indicating that fewer entities have two connections.\nFurther decrease is observed for nodes with degrees 3, 4, and 5, having counts of 1,100, 447, and 257 respectively. This consistent decline suggests that entities with many connections are quite rare in this network.\nLastly, entities with a degree of 5 are the rarest in the network. It may indicate highly connected entities or potential hubs in the network. Overall, the degree distribution of this network suggests a sparse and potentially disconnected network structure, which might present challenges in identifying broad structural anomalies. However, it also helps highlight entities with higher degrees as potential points of interest."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#proportion-of-nodes-in-each-country",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#proportion-of-nodes-in-each-country",
    "title": "Take-home Exercise 3",
    "section": "2.3 Proportion of Nodes in each ‘Country’",
    "text": "2.3 Proportion of Nodes in each ‘Country’\n\n\nA Glimpse into the Code\n# Calculating the number of nodes in each country\ncountry_nodes &lt;- MC3_Nodes %&gt;%\n  count(country) %&gt;%\n  arrange(desc(n)) %&gt;%\n  head(10)\n\n\np1 &lt;- ggplot(country_nodes, aes(reorder(country, -n), n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(title = \"Top 10 Countries by Node Count\", x = \"Country\", y = \"Node Count\") +\n  coord_flip() +\n  theme_minimal() +\n  theme(plot.background = element_rect(fill = \"seashell\"),\n        panel.grid.major = element_line(color = \"grey80\"),\n        panel.grid.minor = element_blank(),\n        legend.position = \"top\",\n        text = element_text(size = 12, face = \"bold\"),\n        plot.title = element_text(hjust = 0.5)) \n\ngp1 &lt;- ggplotly(p1)\n\ngp1\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe country with the most nodes in the graph is ZH, accounting for 22,439 nodes. This significant concentration indicates that ZH is a major player within the network and likely plays a crucial role in the industry.\nThe second most represented country is Oceanus, with 2,143 nodes. While this is considerably less than ZH, it still represents a substantial number of nodes and suggests that Oceanus also holds a significant position within the network.\nThe third most represented country is Marebak, with 742 nodes. Despite having less than a third of the nodes compared to Oceanus and a considerably smaller number compared to ZH, Marebak still has a noteworthy presence within the network.\nOverall, these results suggest a significant concentration of nodes within a few countries, specifically ZH, Oceanus, and Marebak. This could potentially indicate centralization of activities within these regions. Future investigations could help in understanding what specific roles these countries play in the network, and how their large presence may impact the dynamics of the entire network."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#centrality",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#centrality",
    "title": "Take-home Exercise 3",
    "section": "2.4 Centrality",
    "text": "2.4 Centrality\n\nPrep Edge and NodeTidyGraphPlot\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- MC3_Edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- MC3_Edges %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nMC3_Nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;%\n  left_join(MC3_Nodes,\n            unmatched = \"drop\")\n\n\n\n\n\n\nA Glimpse into the Code\nMC3_Graph &lt;- tbl_graph(nodes = MC3_Nodes1,\n                       edges = MC3_Edges,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\n\n\n\n\n\nA Glimpse into the Code\nMC3_Graph %&gt;%\n  filter(betweenness_centrality &gt;= 100000) %&gt;%\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10))+\n  theme_graph(background = \"seashell\")"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#top-5-country-by-revenue",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#top-5-country-by-revenue",
    "title": "Take-home Exercise 3",
    "section": "2.5 Top 5 Country by Revenue",
    "text": "2.5 Top 5 Country by Revenue\n\n\nA Glimpse into the Code\ntop_5 &lt;- MC3_Nodes %&gt;%\n  group_by(country) %&gt;%\n  summarise(total_revenue = sum(revenue_omu, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_revenue)) %&gt;%\n  head(5)\n# Filtering\ntop_countries_5 &lt;- MC3_Nodes[MC3_Nodes$country %in% top_5$country, ]\n\n# Grouping by country and company, and calculating total revenue per company\ntop_countries_5 &lt;- top_countries_5 %&gt;%\n  filter(type==\"Company\") %&gt;%\n  group_by(country, id) %&gt;%\n  summarise(company_revenue = sum(revenue_omu, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  arrange(country, desc(company_revenue))\n\n# For each country, keep only the company with the highest revenue\ntop_countries_5 &lt;- top_countries_5 %&gt;%\n  group_by(country) %&gt;%\n  slice_max(order_by = company_revenue, n = 5)\n\n\ntreemap(top_countries_5,\n        index = c(\"country\", \"id\"),\n        vSize = \"company_revenue\",\n        vColor = \"company_revenue\",\n        palette = \"Paired\",\n        border.lwds = 2,\n        border.col = \"white\",\n        title = \"Top Companies by Revenue in Top 5 Countries\",\n        fontsize.labels = c(14, 10),\n        fontfamily.labels = \"Arial\", \n        fontcolor.labels = c(\"white\", \"black\"),\n        align.labels = list(\n                      c(\"center\", \"center\"),\n                      c(\"left\", \"top\")\n        ), \n        position.legend = \"bottom\"\n    \n)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBelow treemap provides a visual representation of the companies that generate the highest revenues in their respective countries.The top 5 countries were selected based on total revenue. In these selected countries, companies were further sorted and the top revenue-generating companies were identified.\nThe findings from the treemap are as follows:\n\nThe majority of the highest revenue-generating companies are registered in the country labeled as ‘ZH’.\nAmong these, the top 3 companies in terms of revenue generated have been identified as ‘Jones LLC’, ‘Patton Ltd’, and ‘Ramirez,Gallaghar and Jhonson’ Group.\nThe dataset also indicates that in the ‘Utoporiana’ and ‘Oceanus’ countries, the ‘Assam Limited Liability Company’ and ‘Aqua Advancements Sashimi SE Express’ are the top revenue earners respectively."
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#tokenization",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#tokenization",
    "title": "Take-home Exercise 3",
    "section": "2.5 Tokenization",
    "text": "2.5 Tokenization\nCalculating number of times the word fish appeared in the field product_services.\n\n\nA Glimpse into the Code\nMC3_Nodes %&gt;% \n    mutate(n_fish = str_count(product_services, \"fish\")) \n\n\n# A tibble: 27,622 × 6\n   id                          country type  revenue_omu product_services n_fish\n   &lt;chr&gt;                       &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;             &lt;int&gt;\n 1 Jones LLC                   ZH      Comp…  310612303. Automobiles           0\n 2 Coleman, Hall and Lopez     ZH      Comp…  162734684. Passenger cars,…      0\n 3 Aqua Advancements Sashimi … Oceanus Comp…  115004667. Holding firm wh…      0\n 4 Makumba Ltd. Liability Co   Utopor… Comp…   90986413. Car service, ca…      0\n 5 Taylor, Taylor and Farrell  ZH      Comp…   81466667. Fully electric …      0\n 6 Harmon, Edwards and Bates   ZH      Comp…   75070435. Discount superm…      0\n 7 Punjab s Marine conservati… Riodel… Comp…   72167572. Beef, pork, chi…      0\n 8 Assam   Limited Liability … Utopor… Comp…   72162317. Power and Gas s…      0\n 9 Ianira Starfish Sagl Import Rio Is… Comp…   68832979. Light commercia…      0\n10 Moran, Lewis and Jimenez    ZH      Comp…   65592906. Automobiles, tr…      0\n# ℹ 27,612 more rows\n\n\nTokenisation is the process of breaking up a given text into units called tokens. Tokens can be individual words, phrases or even whole sentences. In the process of tokenisation, some characters like punctuation marks may be discarded. The tokens usually become the input for the processes like parsing and text mining.\nIn the code chunk below, unnest_token() of tidytext is used to split text in product_services field into words.\n\nTokenizationStopWordsTop 50 WordsWordCloudHostogram of Top 15 Words\n\n\n\n\nA Glimpse into the Code\ntoken_nodes &lt;- MC3_Nodes %&gt;%\n  unnest_tokens(word, \n                product_services)\n\n\nTop 15 words:\n\n\nA Glimpse into the Code\np &lt;- token_nodes %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(15) %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n  labs(x = \"Count\",\n       y = \"Unique words\",\n       title = \"Count of unique words found in product_services field\") +\n  theme(plot.background = element_rect(fill = \"seashell\"))\n\nggplotly(p)\n\n\n\n\n\n\nThe bar chart reveals that the unique words contains some words that may not be useful to use. For instance “a” and “to”. In the word of text mining we call those words stop words. You want to remove these words from your analysis as they are fillers used to compose a sentence.\nThe tidytext package has a function called stop_words that will help us clean up stop words.\n\n\n\n\nA Glimpse into the Code\nstopwords_removed &lt;- token_nodes %&gt;% \n  anti_join(stop_words)\n\n\n\n\n\n\n\n\nTip\n\n\n\nThere are two processes:\n\nLoad the stop_words data included with tidytext. This data is simply a list of words that you may want to remove in a natural language analysis.\nThen anti_join() of dplyr package is used to remove all stop words from the analysis.\n\n\n\nChecking the Top50 words and their counts\n\n\nA Glimpse into the Code\ntop_50 &lt;- stopwords_removed %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(50)\n\nprint(top_50)\n\n\n# A tibble: 50 × 2\n   word          n\n   &lt;chr&gt;     &lt;int&gt;\n 1 0         18959\n 2 character 18959\n 3 unknown    4645\n 4 products   1860\n 5 fish        740\n 6 seafood     622\n 7 frozen      467\n 8 services    429\n 9 food        345\n10 related     329\n# ℹ 40 more rows\n\n\n\n\nRemoving the unwanted words like 0, Character and Unknown from the stopwords_removed\n\n\nA Glimpse into the Code\nfiltered_words &lt;- stopwords_removed %&gt;%\n  filter(!(word %in% c(\"0\", \"character\", \"unknown\")))\n\n\nChecking Top 50 words in filtered Words\n\n\nA Glimpse into the Code\ntop_50 &lt;- filtered_words %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(50)\n\nprint(top_50)\n\n\n# A tibble: 51 × 2\n   word          n\n   &lt;chr&gt;     &lt;int&gt;\n 1 products   1860\n 2 fish        740\n 3 seafood     622\n 4 frozen      467\n 5 services    429\n 6 food        345\n 7 related     329\n 8 equipment   309\n 9 fresh       276\n10 salmon      252\n# ℹ 41 more rows\n\n\n\n\n\n\nA Glimpse into the Code\nset.seed(1234)\nfiltered_words %&gt;%\n  count(word) %&gt;%\n  with(wordcloud(word, n, max.words = 50))\n\n\n\n\n\n\n\n\n\nA Glimpse into the Code\np &lt;- filtered_words %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  top_n(15) %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(x = word, y = n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip() +\n  labs(x = \"Count\",\n       y = \"Unique words\",\n       title = \"Count of unique words found in product_services field\") +\n  theme(plot.background = element_rect(fill = \"seashell\"))\n\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\nBetweenness Centrality on top 15 Words\nIn our nodes dataset, we have a unique column named ‘product_services’, which isn’t available in the edges dataset. To perform our analysis, we need to consider 15 specific words having highest count and identify the nodes where these words are mentioned in the ‘product_services’ column.\nAfter identifying and filtering these particular nodes, we’ll utilize them as a reference for filtering our edges dataset. Specifically, we’ll only keep the edges where the ‘source’ or ‘target’ matches with the ID of our filtered nodes. This method allows us to create a network subset that’s related to our specific words from the ‘product_services’ column.\n\n\nA Glimpse into the Code\ntop_words &lt;- c(\"products\", \"fish\", \"seafood\", \"frozen\", \"services\", \n               \"food\", \"related\", \"equipment\", \"fresh\", \"salmon\", \n               \"accessories\", \"materials\", \"systems\", \"freight\") \n\n# Filtering nodes that contain the top words in the product_services column\nMC3_NodesFilter &lt;- MC3_Nodes %&gt;% \n  filter(str_detect(product_services, paste(top_words, collapse = \"|\")))\n\n# Filtering  edges where the source or target is in the filtered nodes\n# Filtering edges where the source or target is in the filtered nodes\nMC3_EdgeFilter &lt;- MC3_Edges %&gt;% \n  filter(source %in% MC3_NodesFilter$id | target %in% MC3_NodesFilter$id)\n\n\n\n\nA Glimpse into the Code\nid1 &lt;- MC3_EdgeFilter %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- MC3_EdgeFilter %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nMC3_Nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;%\n  left_join(MC3_Nodes,\n            unmatched = \"drop\")\n\n\nMC3_G &lt;- tbl_graph(nodes = MC3_Nodes1,\n                       edges = MC3_EdgeFilter,\n                       directed = FALSE)%&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness()\n        \n  )\n\n\nBetweenness centrality \nBetweenness centrality measures the number of times a node acts as a bridge along the shortest path between two other nodes. It is useful for identifying nodes that serve as a connector or broker within a network. In illegal fishing, a node with high betweenness centrality might represent a key intermediary, such as a specific ship or company that’s heavily involved in transporting or selling illegal catch.\n\n\nA Glimpse into the Code\ndegrees &lt;- degree(MC3_G, mode = \"all\")\n\nMC3_G_filtered &lt;- MC3_G %&gt;%\n  activate(nodes) %&gt;%\n  filter(betweenness_centrality &gt;= 10000)  \n\nMC3_G_filtered %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(membership(cluster_louvain(.)))) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(size = betweenness_centrality,\n                      color = community,  # Use the community variable for color\n                      alpha = 0.5), show.legend = TRUE) +\n  scale_size_continuous(range = c(1, 10)) +\n  labs(title = \"Betweenness centrality\") + \n  theme(plot.background = element_rect(fill = \"seashell\"))"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#voilin-plot-type-by-revenue",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#voilin-plot-type-by-revenue",
    "title": "Take-home Exercise 3",
    "section": "2.6 Voilin Plot Type by Revenue",
    "text": "2.6 Voilin Plot Type by Revenue\nThe violin plot visualizes the distribution of a numerical variable (revenue_omu) across different categories (type). It provides information on the central tendency, variability, and distributional shape of the revenue data for each type.\n\n\nA Glimpse into the Code\np &lt;- ggplot(MC3_Nodes1, aes(x = type, y = revenue_omu)) +\n  geom_violin(trim = FALSE) +\n  labs(x = \"Type\", y = \"Revenue OMU\") +\n  theme(plot.background = element_rect(fill = \"seashell\")) +\n  scale_y_continuous(labels = scales::comma) +\n  coord_flip()\n\n\nplotly::ggplotly(p)\n\n\n\n\n\n\nAdditionally, created another violin plot specifically for ‘beneficial owner’ type because it has more revenue than the rest, this would allow a more detailed examination of the revenue distribution for this specific type.\n\n\nA Glimpse into the Code\n# Filter data\nMC3_Nodes1_filtered &lt;- MC3_Nodes1 %&gt;%\n  filter(type %in% c(\"Beneficial Owner\"))\n\n# Create the violin plot\np &lt;- ggplot(MC3_Nodes1_filtered, aes(x = type, y = revenue_omu)) +\n  geom_violin(trim = FALSE) +\n  labs(x = \"Type\", y = \"Revenue OMU\") +\n  theme(plot.background = element_rect(fill = \"seashell\")) +\n  scale_y_continuous(labels = scales::comma) +\n  coord_flip()\n\n# Convert to interactive plot\nplotly::ggplotly(p)"
  },
  {
    "objectID": "Takehome Exercise/Takehome Ex 3/Takehome3.html#recommendations-limitations-and-takeaways",
    "href": "Takehome Exercise/Takehome Ex 3/Takehome3.html#recommendations-limitations-and-takeaways",
    "title": "Take-home Exercise 3",
    "section": "Recommendations, Limitations and Takeaways",
    "text": "Recommendations, Limitations and Takeaways\nRECOMMENDATIONS\n\nDeep Dive into Entities with High Degrees: Given the sparsity of the network, entities with higher degrees can be seen as significant connectors. A deeper dive into these entities could provide more valuable insights. What type of entities are they? How do they connect different parts of the network? What role do they play in the context of fishing business and potential IUU activities?\nCountry-Specific Analysis: Given the concentration of nodes in a few countries (especially ZH), it would be valuable to conduct a more detailed country-specific analysis. Understanding the specific roles these countries play in the network and how their large presence impacts the dynamics of the entire network could provide valuable insights.\nRevenue-Based Analysis: The treemap visualization and violin plots provided valuable insights into the revenue patterns across different companies and types of entities. A more detailed revenue-based analysis could be performed, exploring the relationship between revenue and other attributes or network properties.\n\nLIMITATIONS\n\nNetwork Sparsity: The network appears to be quite sparse, potentially indicating a disconnected network structure. This might present challenges in identifying broad structural anomalies or overarching patterns.\n`Limited Attributes for Analysis:The lack of attributes limit the depth and breadth of the analysis. For example, attributes related to the nature and volume of fishing activities, legal status, historical data, etc., could have provided additional dimensions for analysis.\n\nKEY TAKEAWAYS\n\nSignificance of Network Measures: Network measures such as degree and betweenness centrality can provide valuable insights into the roles and importance of nodes within a network. High-degree nodes and nodes with high betweenness centrality can be of particular interest in the context of IUU fishing activities.\nRole of Textual Data: The analysis also highlighted the potential of textual data. The use of specific words in the ‘product_services’ column allowed for a more targeted analysis and extraction of a relevant subset of the network.\nImportance of Revenue Analysis: The analysis of revenue data revealed patterns and anomalies that can be indicative of potential IUU activities. Companies generating disproportionately high revenues and the revenue patterns of specific types of entities are worth further investigation."
  }
]